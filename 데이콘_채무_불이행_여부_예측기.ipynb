{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cjsdudwls1/simple_things/blob/main/%EB%8D%B0%EC%9D%B4%EC%BD%98_%EC%B1%84%EB%AC%B4_%EB%B6%88%EC%9D%B4%ED%96%89_%EC%97%AC%EB%B6%80_%EC%98%88%EC%B8%A1%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 파일 로드"
      ],
      "metadata": {
        "id": "kDtDaBNLpB7u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lgGTwTlafVIa",
        "outputId": "c6e9f8eb-e85b-44c5-f7db-902524484bed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           UID 주거 형태      연간 소득 현재 직장 근속 연수  체납 세금 압류 횟수  개설된 신용계좌 수  \\\n",
            "0  TRAIN_00000    자가  1941337.5      10년 이상          0.0           9   \n",
            "1  TRAIN_00001    월세  1979505.0      10년 이상          0.0           5   \n",
            "2  TRAIN_00002    월세  1356381.0          4년          0.0          12   \n",
            "3  TRAIN_00003    월세  1049017.5          6년          0.0          15   \n",
            "4  TRAIN_00004    월세  4320217.5          2년          0.0          11   \n",
            "\n",
            "   신용 거래 연수   최대 신용한도  신용 문제 발생 횟수  마지막 연체 이후 경과 개월 수  개인 파산 횟수  대출 목적  \\\n",
            "0      13.4  400597.5            0                 24         1  부채 통합   \n",
            "1      15.1  360679.5            0                 11         0  부채 통합   \n",
            "2      18.8  491770.5            1                 74         3  부채 통합   \n",
            "3      14.8  411546.0            1                 22         1  부채 통합   \n",
            "4      26.1  895288.5            0                 32         0  부채 통합   \n",
            "\n",
            "  대출 상환 기간   현재 대출 잔액  현재 미상환 신용액  월 상환 부채액  신용 점수  채무 불이행 여부  \n",
            "0    단기 상환   390903.0    225457.5    8806.5    767          0  \n",
            "1    단기 상환  1002184.5     64749.0   24961.5    767          0  \n",
            "2    단기 상환   227775.0    487644.0   12069.0    800          1  \n",
            "3    단기 상환   251383.5    413211.0   31749.0    796          1  \n",
            "4    장기 상환  1163176.5     78991.5    5862.0    751          0  \n"
          ]
        }
      ],
      "source": [
        "# prompt: /content/train.csv 가져와서 \"train_df\" 로 로드하라\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train.csv')\n",
        "print(train_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eb-AGstignQW",
        "outputId": "76758021-6417-42df-bd52-b119d6d35910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         UID            주거 형태      연간 소득 현재 직장 근속 연수  체납 세금 압류 횟수  개설된 신용계좌 수  \\\n",
            "0  TEST_0000               월세  1560090.0      10년 이상          0.0          13   \n",
            "1  TEST_0001  주택 담보 대출 (거주 중)  2102616.0          2년          0.0           9   \n",
            "2  TEST_0002  주택 담보 대출 (거주 중)  2477989.5      10년 이상          0.0          11   \n",
            "3  TEST_0003  주택 담보 대출 (거주 중)  1571091.0          6년          0.0           7   \n",
            "4  TEST_0004  주택 담보 대출 (거주 중)  2290260.0      10년 이상          0.0          19   \n",
            "\n",
            "   신용 거래 연수    최대 신용한도  신용 문제 발생 횟수  마지막 연체 이후 경과 개월 수  개인 파산 횟수  대출 목적  \\\n",
            "0      12.0   495561.0            0                 18         0     기타   \n",
            "1      29.0   580833.0            0                 40         0  부채 통합   \n",
            "2      26.5   995841.0            0                 44         0  부채 통합   \n",
            "3      34.4   601656.0            0                 45         0  부채 통합   \n",
            "4      25.0  1954623.0            0                 14         0  부채 통합   \n",
            "\n",
            "  대출 상환 기간  현재 대출 잔액  현재 미상환 신용액  월 상환 부채액  신용 점수  \n",
            "0    단기 상환  376332.0    133522.5   29641.5    736  \n",
            "1    장기 상환  830379.0    302983.5   20151.0    718  \n",
            "2    장기 상환  877635.0    379278.0   13113.0    722  \n",
            "3    단기 상환  487278.0    275395.5   11679.0    762  \n",
            "4    단기 상환  397782.0    742767.0   42370.5    775  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/test.csv')\n",
        "print(test_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 수치형(numerical) 변수에 대한 Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "zn7QFwO_gTFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 수치형 변수만 선택\n",
        "numerical_features = train_df.select_dtypes(include=['number']).columns\n",
        "\n",
        "# 각 수치형 변수에 대한 통계 분석\n",
        "for feature in numerical_features:\n",
        "    print(f'===== {feature} 분석 =====')\n",
        "\n",
        "    # 기본 통계량\n",
        "    print(f'기본 통계:')\n",
        "    print(f'- 개수: {train_df[feature].count()}')\n",
        "    print(f'- 최대값: {train_df[feature].max()}')\n",
        "    print(f'- 최소값: {train_df[feature].min()}')\n",
        "    print(f'- 평균값: {train_df[feature].mean():.4f}')\n",
        "    print(f'- 중앙값: {train_df[feature].median():.4f}')\n",
        "    print(f'- 표준편차: {train_df[feature].std():.4f}')\n",
        "\n",
        "    # 분위수 계산\n",
        "    q1 = train_df[feature].quantile(0.25)\n",
        "    q2 = train_df[feature].quantile(0.50)  # 중앙값과 동일\n",
        "    q3 = train_df[feature].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "\n",
        "    print(f'\\n분위수:')\n",
        "    print(f'- 1사분위수(Q1): {q1:.4f}')\n",
        "    print(f'- 2사분위수(Q2, 중앙값): {q2:.4f}')\n",
        "    print(f'- 3사분위수(Q3): {q3:.4f}')\n",
        "    print(f'- IQR(Q3-Q1): {iqr:.4f}')\n",
        "\n",
        "    # 이상치 계산\n",
        "    lower_bound = q1 - 1.5 * iqr\n",
        "    upper_bound = q3 + 1.5 * iqr\n",
        "\n",
        "    outliers = train_df[(train_df[feature] < lower_bound) | (train_df[feature] > upper_bound)]\n",
        "    lower_outliers = train_df[train_df[feature] < lower_bound]\n",
        "    upper_outliers = train_df[train_df[feature] > upper_bound]\n",
        "\n",
        "    print(f'\\n이상치 정보:')\n",
        "    print(f'- 이상치 경계: ({lower_bound:.4f}, {upper_bound:.4f})')\n",
        "    print(f'- 전체 이상치 개수: {len(outliers)} ({len(outliers) / len(train_df) * 100:.2f}%)')\n",
        "    print(f'- 하한 이상치 개수: {len(lower_outliers)} ({len(lower_outliers) / len(train_df) * 100:.2f}%)')\n",
        "    print(f'- 상한 이상치 개수: {len(upper_outliers)} ({len(upper_outliers) / len(train_df) * 100:.2f}%)')\n",
        "\n",
        "    # 이상치가 있는 경우 샘플 출력\n",
        "    if len(outliers) > 0:\n",
        "        print(f'\\n이상치 샘플 (최대 5개):')\n",
        "        print(outliers.head()[feature].to_string())\n",
        "\n",
        "        # 극단값 5개 출력\n",
        "        print(f'\\n최소값 5개:')\n",
        "        print(train_df[feature].nsmallest(5).to_string())\n",
        "\n",
        "        print(f'\\n최대값 5개:')\n",
        "        print(train_df[feature].nlargest(5).to_string())\n",
        "\n",
        "    # 분포 특성 (왜도, 첨도)\n",
        "    skewness = train_df[feature].skew()\n",
        "    kurtosis = train_df[feature].kurt()\n",
        "\n",
        "    print(f'\\n분포 특성:')\n",
        "    print(f'- 왜도(Skewness): {skewness:.4f}')\n",
        "    if skewness > 0.5:\n",
        "        print('  (양의 왜도: 오른쪽으로 긴 꼬리를 가진 분포)')\n",
        "    elif skewness < -0.5:\n",
        "        print('  (음의 왜도: 왼쪽으로 긴 꼬리를 가진 분포)')\n",
        "    else:\n",
        "        print('  (대칭에 가까운 분포)')\n",
        "\n",
        "    print(f'- 첨도(Kurtosis): {kurtosis:.4f}')\n",
        "    if kurtosis > 3:\n",
        "        print('  (정규분포보다 뾰족한 분포)')\n",
        "    else:\n",
        "        print('  (정규분포보다 완만한 분포)')\n",
        "\n",
        "    # 결측치 정보\n",
        "    null_count = train_df[feature].isnull().sum()\n",
        "    print(f'\\n결측치 정보:')\n",
        "    print(f'- 결측치 개수: {null_count} ({null_count / len(train_df) * 100:.2f}%)')\n",
        "\n",
        "    # 구분선 출력\n",
        "    print('\\n' + '=' * 50 + '\\n')"
      ],
      "metadata": {
        "id": "Tt7eUrSjsXl2",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b814d886-55b4-4bba-f977-f402f7068011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== 연간 소득 분석 =====\n",
            "기본 통계:\n",
            "- 개수: 10000\n",
            "- 최대값: 17229747.0\n",
            "- 최소값: 267621.0\n",
            "- 평균값: 2163958.8841\n",
            "- 중앙값: 1743222.7500\n",
            "- 표준편차: 1434429.6820\n",
            "\n",
            "분위수:\n",
            "- 1사분위수(Q1): 1311437.2500\n",
            "- 2사분위수(Q2, 중앙값): 1743222.7500\n",
            "- 3사분위수(Q3): 2447664.0000\n",
            "- IQR(Q3-Q1): 1136226.7500\n",
            "\n",
            "이상치 정보:\n",
            "- 이상치 경계: (-392902.8750, 4152004.1250)\n",
            "- 전체 이상치 개수: 908 (9.08%)\n",
            "- 하한 이상치 개수: 0 (0.00%)\n",
            "- 상한 이상치 개수: 908 (9.08%)\n",
            "\n",
            "이상치 샘플 (최대 5개):\n",
            "4     4320217.5\n",
            "5     5395734.0\n",
            "13    4910103.0\n",
            "20    4861900.5\n",
            "58    4607970.0\n",
            "\n",
            "최소값 5개:\n",
            "8457    267621.0\n",
            "4707    298708.5\n",
            "5336    358485.0\n",
            "9026    360528.0\n",
            "6614    376816.5\n",
            "\n",
            "최대값 5개:\n",
            "8386    17229747.0\n",
            "6790    16497990.0\n",
            "1518    16246152.0\n",
            "4013    15618802.5\n",
            "3995    14082696.0\n",
            "\n",
            "분포 특성:\n",
            "- 왜도(Skewness): 2.9240\n",
            "  (양의 왜도: 오른쪽으로 긴 꼬리를 가진 분포)\n",
            "- 첨도(Kurtosis): 14.0349\n",
            "  (정규분포보다 뾰족한 분포)\n",
            "\n",
            "결측치 정보:\n",
            "- 결측치 개수: 0 (0.00%)\n",
            "\n",
            "==================================================\n",
            "\n",
            "===== 체납 세금 압류 횟수 분석 =====\n",
            "기본 통계:\n",
            "- 개수: 10000\n",
            "- 최대값: 7.0\n",
            "- 최소값: 0.0\n",
            "- 평균값: 0.1993\n",
            "- 중앙값: 0.0000\n",
            "- 표준편차: 0.7143\n",
            "\n",
            "분위수:\n",
            "- 1사분위수(Q1): 0.0000\n",
            "- 2사분위수(Q2, 중앙값): 0.0000\n",
            "- 3사분위수(Q3): 0.0000\n",
            "- IQR(Q3-Q1): 0.0000\n",
            "\n",
            "이상치 정보:\n",
            "- 이상치 경계: (0.0000, 0.0000)\n",
            "- 전체 이상치 개수: 1174 (11.74%)\n",
            "- 하한 이상치 개수: 0 (0.00%)\n",
            "- 상한 이상치 개수: 1174 (11.74%)\n",
            "\n",
            "이상치 샘플 (최대 5개):\n",
            "5     1.0\n",
            "29    1.0\n",
            "42    1.0\n",
            "43    1.0\n",
            "70    1.0\n",
            "\n",
            "최소값 5개:\n",
            "0    0.0\n",
            "1    0.0\n",
            "2    0.0\n",
            "3    0.0\n",
            "4    0.0\n",
            "\n",
            "최대값 5개:\n",
            "1244    7.0\n",
            "1950    7.0\n",
            "4516    7.0\n",
            "4520    7.0\n",
            "5125    7.0\n",
            "\n",
            "분포 특성:\n",
            "- 왜도(Skewness): 5.0252\n",
            "  (양의 왜도: 오른쪽으로 긴 꼬리를 가진 분포)\n",
            "- 첨도(Kurtosis): 28.6801\n",
            "  (정규분포보다 뾰족한 분포)\n",
            "\n",
            "결측치 정보:\n",
            "- 결측치 개수: 0 (0.00%)\n",
            "\n",
            "==================================================\n",
            "\n",
            "===== 개설된 신용계좌 수 분석 =====\n",
            "기본 통계:\n",
            "- 개수: 10000\n",
            "- 최대값: 35\n",
            "- 최소값: 2\n",
            "- 평균값: 12.2489\n",
            "- 중앙값: 12.0000\n",
            "- 표준편차: 4.6206\n",
            "\n",
            "분위수:\n",
            "- 1사분위수(Q1): 9.0000\n",
            "- 2사분위수(Q2, 중앙값): 12.0000\n",
            "- 3사분위수(Q3): 15.0000\n",
            "- IQR(Q3-Q1): 6.0000\n",
            "\n",
            "이상치 정보:\n",
            "- 이상치 경계: (0.0000, 24.0000)\n",
            "- 전체 이상치 개수: 182 (1.82%)\n",
            "- 하한 이상치 개수: 0 (0.00%)\n",
            "- 상한 이상치 개수: 182 (1.82%)\n",
            "\n",
            "이상치 샘플 (최대 5개):\n",
            "116    27\n",
            "140    28\n",
            "171    28\n",
            "175    26\n",
            "197    30\n",
            "\n",
            "최소값 5개:\n",
            "337     2\n",
            "7700    2\n",
            "9830    2\n",
            "161     3\n",
            "1138    3\n",
            "\n",
            "최대값 5개:\n",
            "6951    35\n",
            "4944    33\n",
            "7055    33\n",
            "1679    32\n",
            "2950    32\n",
            "\n",
            "분포 특성:\n",
            "- 왜도(Skewness): 0.9126\n",
            "  (양의 왜도: 오른쪽으로 긴 꼬리를 가진 분포)\n",
            "- 첨도(Kurtosis): 1.0344\n",
            "  (정규분포보다 완만한 분포)\n",
            "\n",
            "결측치 정보:\n",
            "- 결측치 개수: 0 (0.00%)\n",
            "\n",
            "==================================================\n",
            "\n",
            "===== 신용 거래 연수 분석 =====\n",
            "기본 통계:\n",
            "- 개수: 10000\n",
            "- 최대값: 51.7\n",
            "- 최소값: 6.0\n",
            "- 평균값: 19.8794\n",
            "- 중앙값: 17.9500\n",
            "- 표준편차: 7.2067\n",
            "\n",
            "분위수:\n",
            "- 1사분위수(Q1): 14.6000\n",
            "- 2사분위수(Q2, 중앙값): 17.9500\n",
            "- 3사분위수(Q3): 24.1000\n",
            "- IQR(Q3-Q1): 9.5000\n",
            "\n",
            "이상치 정보:\n",
            "- 이상치 경계: (0.3500, 38.3500)\n",
            "- 전체 이상치 개수: 194 (1.94%)\n",
            "- 하한 이상치 개수: 0 (0.00%)\n",
            "- 상한 이상치 개수: 194 (1.94%)\n",
            "\n",
            "이상치 샘플 (최대 5개):\n",
            "20     39.2\n",
            "86     41.1\n",
            "134    42.3\n",
            "181    41.6\n",
            "190    39.0\n",
            "\n",
            "최소값 5개:\n",
            "9317    6.0\n",
            "2597    6.3\n",
            "8021    6.6\n",
            "9460    6.7\n",
            "524     6.9\n",
            "\n",
            "최대값 5개:\n",
            "1882    51.7\n",
            "1352    49.4\n",
            "6453    49.0\n",
            "9077    48.9\n",
            "9377    48.7\n",
            "\n",
            "분포 특성:\n",
            "- 왜도(Skewness): 0.9877\n",
            "  (양의 왜도: 오른쪽으로 긴 꼬리를 가진 분포)\n",
            "- 첨도(Kurtosis): 0.6320\n",
            "  (정규분포보다 완만한 분포)\n",
            "\n",
            "결측치 정보:\n",
            "- 결측치 개수: 0 (0.00%)\n",
            "\n",
            "==================================================\n",
            "\n",
            "===== 최대 신용한도 분석 =====\n",
            "기본 통계:\n",
            "- 개수: 10000\n",
            "- 최대값: 23232333.0\n",
            "- 최소값: 0.0\n",
            "- 평균값: 1175264.7378\n",
            "- 중앙값: 767091.0000\n",
            "- 표준편차: 1604199.2152\n",
            "\n",
            "분위수:\n",
            "- 1사분위수(Q1): 448247.6250\n",
            "- 2사분위수(Q2, 중앙값): 767091.0000\n",
            "- 3사분위수(Q3): 1147282.8750\n",
            "- IQR(Q3-Q1): 699035.2500\n",
            "\n",
            "이상치 정보:\n",
            "- 이상치 경계: (-600305.2500, 2195835.7500)\n",
            "- 전체 이상치 개수: 1045 (10.45%)\n",
            "- 하한 이상치 개수: 0 (0.00%)\n",
            "- 상한 이상치 개수: 1045 (10.45%)\n",
            "\n",
            "이상치 샘플 (최대 5개):\n",
            "13    4898010.0\n",
            "20    5406213.0\n",
            "27    4811965.5\n",
            "37    3357504.0\n",
            "61    2524911.0\n",
            "\n",
            "최소값 5개:\n",
            "10    0.0\n",
            "41    0.0\n",
            "53    0.0\n",
            "85    0.0\n",
            "92    0.0\n",
            "\n",
            "최대값 5개:\n",
            "5593    23232333.0\n",
            "3884    21205669.5\n",
            "8985    19505773.5\n",
            "77      18359748.0\n",
            "1036    18164964.0\n",
            "\n",
            "분포 특성:\n",
            "- 왜도(Skewness): 4.4832\n",
            "  (양의 왜도: 오른쪽으로 긴 꼬리를 가진 분포)\n",
            "- 첨도(Kurtosis): 31.2215\n",
            "  (정규분포보다 뾰족한 분포)\n",
            "\n",
            "결측치 정보:\n",
            "- 결측치 개수: 0 (0.00%)\n",
            "\n",
            "==================================================\n",
            "\n",
            "===== 신용 문제 발생 횟수 분석 =====\n",
            "기본 통계:\n",
            "- 개수: 10000\n",
            "- 최대값: 7\n",
            "- 최소값: 0\n",
            "- 평균값: 0.6262\n",
            "- 중앙값: 0.0000\n",
            "- 표준편차: 1.2342\n",
            "\n",
            "분위수:\n",
            "- 1사분위수(Q1): 0.0000\n",
            "- 2사분위수(Q2, 중앙값): 0.0000\n",
            "- 3사분위수(Q3): 1.0000\n",
            "- IQR(Q3-Q1): 1.0000\n",
            "\n",
            "이상치 정보:\n",
            "- 이상치 경계: (-1.5000, 2.5000)\n",
            "- 전체 이상치 개수: 541 (5.41%)\n",
            "- 하한 이상치 개수: 0 (0.00%)\n",
            "- 상한 이상치 개수: 541 (5.41%)\n",
            "\n",
            "이상치 샘플 (최대 5개):\n",
            "21     6\n",
            "52     5\n",
            "83     6\n",
            "97     5\n",
            "105    6\n",
            "\n",
            "최소값 5개:\n",
            "0    0\n",
            "1    0\n",
            "4    0\n",
            "7    0\n",
            "8    0\n",
            "\n",
            "최대값 5개:\n",
            "638     7\n",
            "2238    7\n",
            "3133    7\n",
            "3548    7\n",
            "3927    7\n",
            "\n",
            "분포 특성:\n",
            "- 왜도(Skewness): 2.8055\n",
            "  (양의 왜도: 오른쪽으로 긴 꼬리를 가진 분포)\n",
            "- 첨도(Kurtosis): 8.1980\n",
            "  (정규분포보다 뾰족한 분포)\n",
            "\n",
            "결측치 정보:\n",
            "- 결측치 개수: 0 (0.00%)\n",
            "\n",
            "==================================================\n",
            "\n",
            "===== 마지막 연체 이후 경과 개월 수 분석 =====\n",
            "기본 통계:\n",
            "- 개수: 10000\n",
            "- 최대값: 88\n",
            "- 최소값: 0\n",
            "- 평균값: 30.8892\n",
            "- 중앙값: 28.0000\n",
            "- 표준편차: 20.0116\n",
            "\n",
            "분위수:\n",
            "- 1사분위수(Q1): 14.0000\n",
            "- 2사분위수(Q2, 중앙값): 28.0000\n",
            "- 3사분위수(Q3): 41.0000\n",
            "- IQR(Q3-Q1): 27.0000\n",
            "\n",
            "이상치 정보:\n",
            "- 이상치 경계: (-26.5000, 81.5000)\n",
            "- 전체 이상치 개수: 27 (0.27%)\n",
            "- 하한 이상치 개수: 0 (0.00%)\n",
            "- 상한 이상치 개수: 27 (0.27%)\n",
            "\n",
            "이상치 샘플 (최대 5개):\n",
            "127    85\n",
            "337    82\n",
            "349    83\n",
            "637    84\n",
            "761    86\n",
            "\n",
            "최소값 5개:\n",
            "50      0\n",
            "196     0\n",
            "521     0\n",
            "793     0\n",
            "1223    0\n",
            "\n",
            "최대값 5개:\n",
            "1562    88\n",
            "761     86\n",
            "1089    86\n",
            "4280    86\n",
            "127     85\n",
            "\n",
            "분포 특성:\n",
            "- 왜도(Skewness): 0.6629\n",
            "  (양의 왜도: 오른쪽으로 긴 꼬리를 가진 분포)\n",
            "- 첨도(Kurtosis): -0.4131\n",
            "  (정규분포보다 완만한 분포)\n",
            "\n",
            "결측치 정보:\n",
            "- 결측치 개수: 0 (0.00%)\n",
            "\n",
            "==================================================\n",
            "\n",
            "===== 개인 파산 횟수 분석 =====\n",
            "기본 통계:\n",
            "- 개수: 10000\n",
            "- 최대값: 3\n",
            "- 최소값: 0\n",
            "- 평균값: 0.3732\n",
            "- 중앙값: 0.0000\n",
            "- 표준편차: 0.8438\n",
            "\n",
            "분위수:\n",
            "- 1사분위수(Q1): 0.0000\n",
            "- 2사분위수(Q2, 중앙값): 0.0000\n",
            "- 3사분위수(Q3): 0.0000\n",
            "- IQR(Q3-Q1): 0.0000\n",
            "\n",
            "이상치 정보:\n",
            "- 이상치 경계: (0.0000, 0.0000)\n",
            "- 전체 이상치 개수: 2114 (21.14%)\n",
            "- 하한 이상치 개수: 0 (0.00%)\n",
            "- 상한 이상치 개수: 2114 (21.14%)\n",
            "\n",
            "이상치 샘플 (최대 5개):\n",
            "0     1\n",
            "2     3\n",
            "3     1\n",
            "6     3\n",
            "12    1\n",
            "\n",
            "최소값 5개:\n",
            "1    0\n",
            "4    0\n",
            "5    0\n",
            "7    0\n",
            "8    0\n",
            "\n",
            "최대값 5개:\n",
            "2     3\n",
            "6     3\n",
            "14    3\n",
            "21    3\n",
            "25    3\n",
            "\n",
            "분포 특성:\n",
            "- 왜도(Skewness): 2.3666\n",
            "  (양의 왜도: 오른쪽으로 긴 꼬리를 가진 분포)\n",
            "- 첨도(Kurtosis): 4.4259\n",
            "  (정규분포보다 뾰족한 분포)\n",
            "\n",
            "결측치 정보:\n",
            "- 결측치 개수: 0 (0.00%)\n",
            "\n",
            "==================================================\n",
            "\n",
            "===== 현재 대출 잔액 분석 =====\n",
            "기본 통계:\n",
            "- 개수: 10000\n",
            "- 최대값: 1373613.0\n",
            "- 최소값: 29176.5\n",
            "- 평균값: 506120.0004\n",
            "- 중앙값: 474341.2500\n",
            "- 표준편차: 283146.2327\n",
            "\n",
            "분위수:\n",
            "- 1사분위수(Q1): 300190.1250\n",
            "- 2사분위수(Q2, 중앙값): 474341.2500\n",
            "- 3사분위수(Q3): 591907.8750\n",
            "- IQR(Q3-Q1): 291717.7500\n",
            "\n",
            "이상치 정보:\n",
            "- 이상치 경계: (-137386.5000, 1029484.5000)\n",
            "- 전체 이상치 개수: 877 (8.77%)\n",
            "- 하한 이상치 개수: 0 (0.00%)\n",
            "- 상한 이상치 개수: 877 (8.77%)\n",
            "\n",
            "이상치 샘플 (최대 5개):\n",
            "4     1163176.5\n",
            "13    1127766.0\n",
            "29    1235440.5\n",
            "47    1270152.0\n",
            "58    1223505.0\n",
            "\n",
            "최소값 5개:\n",
            "6087    29176.5\n",
            "7610    29412.0\n",
            "5363    30472.5\n",
            "1326    34857.0\n",
            "9405    35023.5\n",
            "\n",
            "최대값 5개:\n",
            "7591    1373613.0\n",
            "5320    1356999.0\n",
            "3012    1353348.0\n",
            "5041    1351681.5\n",
            "8567    1349863.5\n",
            "\n",
            "분포 특성:\n",
            "- 왜도(Skewness): 1.0243\n",
            "  (양의 왜도: 오른쪽으로 긴 꼬리를 가진 분포)\n",
            "- 첨도(Kurtosis): 0.5930\n",
            "  (정규분포보다 완만한 분포)\n",
            "\n",
            "결측치 정보:\n",
            "- 결측치 개수: 0 (0.00%)\n",
            "\n",
            "==================================================\n",
            "\n",
            "===== 현재 미상환 신용액 분석 =====\n",
            "기본 통계:\n",
            "- 개수: 10000\n",
            "- 최대값: 3946300.5\n",
            "- 최소값: 0.0\n",
            "- 평균값: 364912.6176\n",
            "- 중앙값: 254793.0000\n",
            "- 표준편차: 353794.1607\n",
            "\n",
            "분위수:\n",
            "- 1사분위수(Q1): 147185.6250\n",
            "- 2사분위수(Q2, 중앙값): 254793.0000\n",
            "- 3사분위수(Q3): 474918.0000\n",
            "- IQR(Q3-Q1): 327732.3750\n",
            "\n",
            "이상치 정보:\n",
            "- 이상치 경계: (-344412.9375, 966516.5625)\n",
            "- 전체 이상치 개수: 660 (6.60%)\n",
            "- 하한 이상치 개수: 0 (0.00%)\n",
            "- 상한 이상치 개수: 660 (6.60%)\n",
            "\n",
            "이상치 샘플 (최대 5개):\n",
            "49     1088926.5\n",
            "93     1048329.0\n",
            "95      997212.0\n",
            "107    1170946.5\n",
            "119    2583391.5\n",
            "\n",
            "최소값 5개:\n",
            "60     0.0\n",
            "85     0.0\n",
            "109    0.0\n",
            "113    0.0\n",
            "407    0.0\n",
            "\n",
            "최대값 5개:\n",
            "944     3946300.5\n",
            "5121    3905895.0\n",
            "3652    3894418.5\n",
            "2224    3778435.5\n",
            "7633    3647731.5\n",
            "\n",
            "분포 특성:\n",
            "- 왜도(Skewness): 3.3060\n",
            "  (양의 왜도: 오른쪽으로 긴 꼬리를 가진 분포)\n",
            "- 첨도(Kurtosis): 19.4237\n",
            "  (정규분포보다 뾰족한 분포)\n",
            "\n",
            "결측치 정보:\n",
            "- 결측치 개수: 0 (0.00%)\n",
            "\n",
            "==================================================\n",
            "\n",
            "===== 월 상환 부채액 분석 =====\n",
            "기본 통계:\n",
            "- 개수: 10000\n",
            "- 최대값: 153574.5\n",
            "- 최소값: 0.0\n",
            "- 평균값: 22367.2808\n",
            "- 중앙값: 20160.0000\n",
            "- 표준편차: 15186.4974\n",
            "\n",
            "분위수:\n",
            "- 1사분위수(Q1): 10893.7500\n",
            "- 2사분위수(Q2, 중앙값): 20160.0000\n",
            "- 3사분위수(Q3): 30647.2500\n",
            "- IQR(Q3-Q1): 19753.5000\n",
            "\n",
            "이상치 정보:\n",
            "- 이상치 경계: (-18736.5000, 60277.5000)\n",
            "- 전체 이상치 개수: 199 (1.99%)\n",
            "- 하한 이상치 개수: 0 (0.00%)\n",
            "- 상한 이상치 개수: 199 (1.99%)\n",
            "\n",
            "이상치 샘플 (최대 5개):\n",
            "13     109195.5\n",
            "67     108526.5\n",
            "73      85537.5\n",
            "125     98065.5\n",
            "197     86530.5\n",
            "\n",
            "최소값 5개:\n",
            "85     0.0\n",
            "186    0.0\n",
            "191    0.0\n",
            "345    0.0\n",
            "392    0.0\n",
            "\n",
            "최대값 5개:\n",
            "330     153574.5\n",
            "1784    135613.5\n",
            "8150    131469.0\n",
            "8639    130071.0\n",
            "1566    126918.0\n",
            "\n",
            "분포 특성:\n",
            "- 왜도(Skewness): 1.5337\n",
            "  (양의 왜도: 오른쪽으로 긴 꼬리를 가진 분포)\n",
            "- 첨도(Kurtosis): 5.2677\n",
            "  (정규분포보다 뾰족한 분포)\n",
            "\n",
            "결측치 정보:\n",
            "- 결측치 개수: 0 (0.00%)\n",
            "\n",
            "==================================================\n",
            "\n",
            "===== 신용 점수 분석 =====\n",
            "기본 통계:\n",
            "- 개수: 10000\n",
            "- 최대값: 825\n",
            "- 최소값: 502\n",
            "- 평균값: 744.2150\n",
            "- 중앙값: 756.0000\n",
            "- 표준편차: 56.9957\n",
            "\n",
            "분위수:\n",
            "- 1사분위수(Q1): 704.0000\n",
            "- 2사분위수(Q2, 중앙값): 756.0000\n",
            "- 3사분위수(Q3): 793.0000\n",
            "- IQR(Q3-Q1): 89.0000\n",
            "\n",
            "이상치 정보:\n",
            "- 이상치 경계: (570.5000, 926.5000)\n",
            "- 전체 이상치 개수: 108 (1.08%)\n",
            "- 하한 이상치 개수: 108 (1.08%)\n",
            "- 상한 이상치 개수: 0 (0.00%)\n",
            "\n",
            "이상치 샘플 (최대 5개):\n",
            "22     542\n",
            "47     529\n",
            "145    564\n",
            "228    533\n",
            "230    556\n",
            "\n",
            "최소값 5개:\n",
            "7654    502\n",
            "6510    505\n",
            "725     511\n",
            "6911    518\n",
            "9908    518\n",
            "\n",
            "최대값 5개:\n",
            "1688    825\n",
            "3087    824\n",
            "5017    824\n",
            "2619    822\n",
            "3923    822\n",
            "\n",
            "분포 특성:\n",
            "- 왜도(Skewness): -0.9804\n",
            "  (음의 왜도: 왼쪽으로 긴 꼬리를 가진 분포)\n",
            "- 첨도(Kurtosis): 0.6063\n",
            "  (정규분포보다 완만한 분포)\n",
            "\n",
            "결측치 정보:\n",
            "- 결측치 개수: 0 (0.00%)\n",
            "\n",
            "==================================================\n",
            "\n",
            "===== 채무 불이행 여부 분석 =====\n",
            "기본 통계:\n",
            "- 개수: 10000\n",
            "- 최대값: 1\n",
            "- 최소값: 0\n",
            "- 평균값: 0.3412\n",
            "- 중앙값: 0.0000\n",
            "- 표준편차: 0.4741\n",
            "\n",
            "분위수:\n",
            "- 1사분위수(Q1): 0.0000\n",
            "- 2사분위수(Q2, 중앙값): 0.0000\n",
            "- 3사분위수(Q3): 1.0000\n",
            "- IQR(Q3-Q1): 1.0000\n",
            "\n",
            "이상치 정보:\n",
            "- 이상치 경계: (-1.5000, 2.5000)\n",
            "- 전체 이상치 개수: 0 (0.00%)\n",
            "- 하한 이상치 개수: 0 (0.00%)\n",
            "- 상한 이상치 개수: 0 (0.00%)\n",
            "\n",
            "분포 특성:\n",
            "- 왜도(Skewness): 0.6700\n",
            "  (양의 왜도: 오른쪽으로 긴 꼬리를 가진 분포)\n",
            "- 첨도(Kurtosis): -1.5514\n",
            "  (정규분포보다 완만한 분포)\n",
            "\n",
            "결측치 정보:\n",
            "- 결측치 개수: 0 (0.00%)\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 범주형(categorical) 변수에 대한 Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "Lb5lYMmioDTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 범주형 변수만 선택\n",
        "categorical_features = train_df.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "# 각 범주형 변수에 대한 분석\n",
        "for feature in categorical_features:\n",
        "    print(f'===== {feature} 분석 =====')\n",
        "\n",
        "    # 기본 정보\n",
        "    print(f'기본 정보:')\n",
        "    print(f'- 총 데이터 수: {train_df[feature].count()}')\n",
        "    print(f'- 결측치 수: {train_df[feature].isnull().sum()} ({train_df[feature].isnull().sum() / len(train_df) * 100:.2f}%)')\n",
        "    print(f'- 고유 범주 수: {train_df[feature].nunique()}')\n",
        "\n",
        "    # 각 범주의 빈도 및 비율\n",
        "    value_counts = train_df[feature].value_counts()\n",
        "    value_percentage = train_df[feature].value_counts(normalize=True) * 100\n",
        "\n",
        "    print(f'\\n범주별 빈도:')\n",
        "    for idx, (value, count) in enumerate(value_counts.items()):\n",
        "        percentage = value_percentage[value]\n",
        "        print(f'- {value}: {count} ({percentage:.2f}%)')\n",
        "        # 상위 10개만 출력\n",
        "        if idx >= 9 and len(value_counts) > 10:\n",
        "            print(f'  ... 그 외 {len(value_counts) - 10}개 범주')\n",
        "            break\n",
        "\n",
        "    # 타겟 변수와의 관계 분석 (채무 불이행 여부와의 관계)\n",
        "    if '채무 불이행 여부' in train_df.columns:\n",
        "        print(f'\\n타겟 변수(채무 불이행 여부)와의 관계:')\n",
        "        target_by_category = train_df.groupby(feature)['채무 불이행 여부'].agg(['count', 'mean', 'sum'])\n",
        "        target_by_category['불이행률(%)'] = target_by_category['mean'] * 100\n",
        "\n",
        "        print(target_by_category.sort_values(by='불이행률(%)', ascending=False))\n",
        "\n",
        "        # 카이제곱 검정 (범주형 변수와 타겟 간의 독립성 검정)\n",
        "        from scipy.stats import chi2_contingency\n",
        "\n",
        "        contingency_table = pd.crosstab(train_df[feature], train_df['채무 불이행 여부'])\n",
        "        chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "        print(f'\\n카이제곱 검정 결과:')\n",
        "        print(f'- 카이제곱 값: {chi2:.4f}')\n",
        "        print(f'- p-value: {p:.4f}')\n",
        "        print(f'- 자유도: {dof}')\n",
        "\n",
        "        if p < 0.05:\n",
        "            print(f'  (p < 0.05: 변수와 타겟 간에 유의한 관계가 있음)')\n",
        "        else:\n",
        "            print(f'  (p >= 0.05: 변수와 타겟 간에 유의한 관계가 없음)')\n",
        "\n",
        "    # 수치형 변수와의 관계 분석 (주요 수치형 변수와의 관계)\n",
        "    if '신용 점수' in train_df.columns:\n",
        "        print(f'\\n주요 수치형 변수와의 관계:')\n",
        "\n",
        "        # 신용 점수와의 관계\n",
        "        credit_by_category = train_df.groupby(feature)['신용 점수'].agg(['count', 'mean', 'median', 'std', 'min', 'max'])\n",
        "        print('\\n신용 점수와의 관계:')\n",
        "        print(credit_by_category)\n",
        "\n",
        "        # 연간 소득과의 관계\n",
        "        if '연간 소득' in train_df.columns:\n",
        "            income_by_category = train_df.groupby(feature)['연간 소득'].agg(['count', 'mean', 'median', 'std', 'min', 'max'])\n",
        "            print('\\n연간 소득과의 관계:')\n",
        "            print(income_by_category)\n",
        "\n",
        "    # 상위 다른 범주형 변수와의 교차분석 (최대 3개)\n",
        "    other_categorical = [col for col in categorical_features if col != feature][:3]\n",
        "    if other_categorical:\n",
        "        print(f'\\n다른 범주형 변수와의 관계:')\n",
        "\n",
        "        for other_feature in other_categorical:\n",
        "            print(f'\\n{other_feature}와(과)의 관계:')\n",
        "            cross_tab = pd.crosstab(\n",
        "                train_df[feature],\n",
        "                train_df[other_feature],\n",
        "                normalize='index'\n",
        "            ) * 100\n",
        "\n",
        "            # 행이 너무 많으면 상위 5개만 출력\n",
        "            if len(cross_tab) > 5:\n",
        "                print(cross_tab.head(5))\n",
        "                print(\"... (행이 너무 많아 상위 5개만 출력)\")\n",
        "            else:\n",
        "                print(cross_tab)\n",
        "\n",
        "    # 시간에 따른 변화 (시간 관련 변수가 있는 경우)\n",
        "    date_columns = [col for col in train_df.columns if 'date' in col.lower() or '일자' in col.lower() or '날짜' in col.lower()]\n",
        "    if date_columns:\n",
        "        date_col = date_columns[0]\n",
        "        print(f'\\n시간에 따른 변화 ({date_col}):')\n",
        "\n",
        "        # 날짜 데이터 형식으로 변환\n",
        "        try:\n",
        "            train_df[date_col] = pd.to_datetime(train_df[date_col])\n",
        "            train_df['year_month'] = train_df[date_col].dt.to_period('M')\n",
        "\n",
        "            # 월별 범주 분포 변화\n",
        "            time_trend = pd.crosstab(\n",
        "                train_df['year_month'],\n",
        "                train_df[feature],\n",
        "                normalize='index'\n",
        "            ) * 100\n",
        "\n",
        "            print(time_trend.head())\n",
        "            if len(time_trend) > 5:\n",
        "                print(\"... (기간이 너무 길어 상위 5개월만 출력)\")\n",
        "        except:\n",
        "            print(\"날짜 변환 중 오류가 발생했습니다.\")\n",
        "\n",
        "    # 데이터 품질 체크\n",
        "    print(f'\\n데이터 품질 검사:')\n",
        "\n",
        "    # 이상한 범주값 체크 (예: 공백, 특수문자만 있는 경우)\n",
        "    unusual_values = [val for val in train_df[feature].unique()\n",
        "                     if isinstance(val, str) and (val.isspace() or val == '' or val == '?' or val == 'unknown')]\n",
        "\n",
        "    if unusual_values:\n",
        "        print(f'- 이상한 범주값: {unusual_values}')\n",
        "        for val in unusual_values:\n",
        "            count = (train_df[feature] == val).sum()\n",
        "            print(f'  {val}: {count}개 ({count / len(train_df) * 100:.2f}%)')\n",
        "    else:\n",
        "        print('- 이상한 범주값 없음')\n",
        "\n",
        "    # 불균형 체크 (가장 많은 범주가 90% 이상인 경우)\n",
        "    most_common = value_percentage.max()\n",
        "    if most_common > 90:\n",
        "        print(f'- 심한 불균형: 가장 많은 범주가 전체의 {most_common:.2f}%')\n",
        "    elif most_common > 70:\n",
        "        print(f'- 불균형: 가장 많은 범주가 전체의 {most_common:.2f}%')\n",
        "    else:\n",
        "        print(f'- 범주 분포가 비교적 균형적임 (최대 비율: {most_common:.2f}%)')\n",
        "\n",
        "    # 구분선 출력\n",
        "    print('\\n' + '=' * 50 + '\\n')\n",
        "\n",
        "# 모든 범주형 변수에 대한 타겟 변수 관계 요약\n",
        "if '채무 불이행 여부' in train_df.columns:\n",
        "    print(\"===== 모든 범주형 변수의 타겟 변수 영향력 요약 =====\")\n",
        "\n",
        "    target_impact = {}\n",
        "\n",
        "    for feature in categorical_features:\n",
        "        # 카이제곱 검정\n",
        "        contingency_table = pd.crosstab(train_df[feature], train_df['채무 불이행 여부'])\n",
        "        chi2, p, _, _ = chi2_contingency(contingency_table)\n",
        "\n",
        "        # 크래머의 V 계수 (관계 강도)\n",
        "        n = len(train_df)\n",
        "        k = min(contingency_table.shape) - 1\n",
        "        cramers_v = np.sqrt(chi2 / (n * k)) if k > 0 else 0\n",
        "\n",
        "        target_impact[feature] = {\n",
        "            'chi2': chi2,\n",
        "            'p_value': p,\n",
        "            'cramers_v': cramers_v\n",
        "        }\n",
        "\n",
        "    # 데이터프레임으로 변환\n",
        "    impact_df = pd.DataFrame.from_dict(target_impact, orient='index')\n",
        "    impact_df = impact_df.sort_values(by='cramers_v', ascending=False)\n",
        "\n",
        "    print(impact_df)\n",
        "    print(\"\\n* cramers_v: 변수와 타겟 간 연관성 강도 (0~1, 높을수록 강한 연관성)\")\n",
        "    print(\"* p_value: 0.05 미만이면 통계적으로 유의미한 관계\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8duWbTvVmeHI",
        "outputId": "71d79e15-a2ab-4bf2-bebb-f296c52b2de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== UID 분석 =====\n",
            "기본 정보:\n",
            "- 총 데이터 수: 10000\n",
            "- 결측치 수: 0 (0.00%)\n",
            "- 고유 범주 수: 10000\n",
            "\n",
            "범주별 빈도:\n",
            "- TRAIN_09983: 1 (0.01%)\n",
            "- TRAIN_09982: 1 (0.01%)\n",
            "- TRAIN_09981: 1 (0.01%)\n",
            "- TRAIN_09980: 1 (0.01%)\n",
            "- TRAIN_09979: 1 (0.01%)\n",
            "- TRAIN_09978: 1 (0.01%)\n",
            "- TRAIN_09977: 1 (0.01%)\n",
            "- TRAIN_09976: 1 (0.01%)\n",
            "- TRAIN_09975: 1 (0.01%)\n",
            "- TRAIN_09974: 1 (0.01%)\n",
            "  ... 그 외 9990개 범주\n",
            "\n",
            "타겟 변수(채무 불이행 여부)와의 관계:\n",
            "             count  mean  sum  불이행률(%)\n",
            "UID                                   \n",
            "TRAIN_09980      1   1.0    1    100.0\n",
            "TRAIN_09976      1   1.0    1    100.0\n",
            "TRAIN_09973      1   1.0    1    100.0\n",
            "TRAIN_09970      1   1.0    1    100.0\n",
            "TRAIN_00028      1   1.0    1    100.0\n",
            "...            ...   ...  ...      ...\n",
            "TRAIN_03408      1   0.0    0      0.0\n",
            "TRAIN_09999      1   0.0    0      0.0\n",
            "TRAIN_09998      1   0.0    0      0.0\n",
            "TRAIN_09997      1   0.0    0      0.0\n",
            "TRAIN_09996      1   0.0    0      0.0\n",
            "\n",
            "[10000 rows x 4 columns]\n",
            "\n",
            "카이제곱 검정 결과:\n",
            "- 카이제곱 값: 10000.0000\n",
            "- p-value: 0.4953\n",
            "- 자유도: 9999\n",
            "  (p >= 0.05: 변수와 타겟 간에 유의한 관계가 없음)\n",
            "\n",
            "주요 수치형 변수와의 관계:\n",
            "\n",
            "신용 점수와의 관계:\n",
            "             count   mean  median  std  min  max\n",
            "UID                                             \n",
            "TRAIN_00000      1  767.0   767.0  NaN  767  767\n",
            "TRAIN_00001      1  767.0   767.0  NaN  767  767\n",
            "TRAIN_00002      1  800.0   800.0  NaN  800  800\n",
            "TRAIN_00003      1  796.0   796.0  NaN  796  796\n",
            "TRAIN_00004      1  751.0   751.0  NaN  751  751\n",
            "...            ...    ...     ...  ...  ...  ...\n",
            "TRAIN_09995      1  755.0   755.0  NaN  755  755\n",
            "TRAIN_09996      1  707.0   707.0  NaN  707  707\n",
            "TRAIN_09997      1  733.0   733.0  NaN  733  733\n",
            "TRAIN_09998      1  696.0   696.0  NaN  696  696\n",
            "TRAIN_09999      1  676.0   676.0  NaN  676  676\n",
            "\n",
            "[10000 rows x 6 columns]\n",
            "\n",
            "연간 소득과의 관계:\n",
            "             count       mean     median  std        min        max\n",
            "UID                                                                \n",
            "TRAIN_00000      1  1941337.5  1941337.5  NaN  1941337.5  1941337.5\n",
            "TRAIN_00001      1  1979505.0  1979505.0  NaN  1979505.0  1979505.0\n",
            "TRAIN_00002      1  1356381.0  1356381.0  NaN  1356381.0  1356381.0\n",
            "TRAIN_00003      1  1049017.5  1049017.5  NaN  1049017.5  1049017.5\n",
            "TRAIN_00004      1  4320217.5  4320217.5  NaN  4320217.5  4320217.5\n",
            "...            ...        ...        ...  ...        ...        ...\n",
            "TRAIN_09995      1  1339473.0  1339473.0  NaN  1339473.0  1339473.0\n",
            "TRAIN_09996      1  2297230.5  2297230.5  NaN  2297230.5  2297230.5\n",
            "TRAIN_09997      1  1221523.5  1221523.5  NaN  1221523.5  1221523.5\n",
            "TRAIN_09998      1  3343584.0  3343584.0  NaN  3343584.0  3343584.0\n",
            "TRAIN_09999      1  2175133.5  2175133.5  NaN  2175133.5  2175133.5\n",
            "\n",
            "[10000 rows x 6 columns]\n",
            "\n",
            "다른 범주형 변수와의 관계:\n",
            "\n",
            "주거 형태와(과)의 관계:\n",
            "주거 형태           월세     자가  주택 담보 대출 (거주 중)  주택 담보 대출 (비거주 중)\n",
            "UID                                                         \n",
            "TRAIN_00000    0.0  100.0              0.0               0.0\n",
            "TRAIN_00001  100.0    0.0              0.0               0.0\n",
            "TRAIN_00002  100.0    0.0              0.0               0.0\n",
            "TRAIN_00003  100.0    0.0              0.0               0.0\n",
            "TRAIN_00004  100.0    0.0              0.0               0.0\n",
            "... (행이 너무 많아 상위 5개만 출력)\n",
            "\n",
            "현재 직장 근속 연수와(과)의 관계:\n",
            "현재 직장 근속 연수  10년 이상   1년  1년 미만     2년   3년     4년   5년     6년   7년   8년   9년\n",
            "UID                                                                          \n",
            "TRAIN_00000   100.0  0.0    0.0    0.0  0.0    0.0  0.0    0.0  0.0  0.0  0.0\n",
            "TRAIN_00001   100.0  0.0    0.0    0.0  0.0    0.0  0.0    0.0  0.0  0.0  0.0\n",
            "TRAIN_00002     0.0  0.0    0.0    0.0  0.0  100.0  0.0    0.0  0.0  0.0  0.0\n",
            "TRAIN_00003     0.0  0.0    0.0    0.0  0.0    0.0  0.0  100.0  0.0  0.0  0.0\n",
            "TRAIN_00004     0.0  0.0    0.0  100.0  0.0    0.0  0.0    0.0  0.0  0.0  0.0\n",
            "... (행이 너무 많아 상위 5개만 출력)\n",
            "\n",
            "대출 목적와(과)의 관계:\n",
            "대출 목적        결혼 자금  고액 구매  교육비   기타  부채 통합  사업 대출  소규모 사업 자금  여행 자금  의료비  \\\n",
            "UID                                                                        \n",
            "TRAIN_00000    0.0    0.0  0.0  0.0  100.0    0.0        0.0    0.0  0.0   \n",
            "TRAIN_00001    0.0    0.0  0.0  0.0  100.0    0.0        0.0    0.0  0.0   \n",
            "TRAIN_00002    0.0    0.0  0.0  0.0  100.0    0.0        0.0    0.0  0.0   \n",
            "TRAIN_00003    0.0    0.0  0.0  0.0  100.0    0.0        0.0    0.0  0.0   \n",
            "TRAIN_00004    0.0    0.0  0.0  0.0  100.0    0.0        0.0    0.0  0.0   \n",
            "\n",
            "대출 목적        이사 비용  자동차 구매  주택 개보수  주택 구매  휴가 비용  \n",
            "UID                                               \n",
            "TRAIN_00000    0.0     0.0     0.0    0.0    0.0  \n",
            "TRAIN_00001    0.0     0.0     0.0    0.0    0.0  \n",
            "TRAIN_00002    0.0     0.0     0.0    0.0    0.0  \n",
            "TRAIN_00003    0.0     0.0     0.0    0.0    0.0  \n",
            "TRAIN_00004    0.0     0.0     0.0    0.0    0.0  \n",
            "... (행이 너무 많아 상위 5개만 출력)\n",
            "\n",
            "데이터 품질 검사:\n",
            "- 이상한 범주값 없음\n",
            "- 범주 분포가 비교적 균형적임 (최대 비율: 0.01%)\n",
            "\n",
            "==================================================\n",
            "\n",
            "===== 주거 형태 분석 =====\n",
            "기본 정보:\n",
            "- 총 데이터 수: 10000\n",
            "- 결측치 수: 0 (0.00%)\n",
            "- 고유 범주 수: 4\n",
            "\n",
            "범주별 빈도:\n",
            "- 월세: 4050 (40.50%)\n",
            "- 주택 담보 대출 (거주 중): 3633 (36.33%)\n",
            "- 자가: 2241 (22.41%)\n",
            "- 주택 담보 대출 (비거주 중): 76 (0.76%)\n",
            "\n",
            "타겟 변수(채무 불이행 여부)와의 관계:\n",
            "                  count      mean   sum    불이행률(%)\n",
            "주거 형태                                             \n",
            "월세                 4050  0.384938  1559  38.493827\n",
            "자가                 2241  0.327532   734  32.753235\n",
            "주택 담보 대출 (거주 중)    3633  0.304707  1107  30.470685\n",
            "주택 담보 대출 (비거주 중)     76  0.157895    12  15.789474\n",
            "\n",
            "카이제곱 검정 결과:\n",
            "- 카이제곱 값: 69.2150\n",
            "- p-value: 0.0000\n",
            "- 자유도: 3\n",
            "  (p < 0.05: 변수와 타겟 간에 유의한 관계가 있음)\n",
            "\n",
            "주요 수치형 변수와의 관계:\n",
            "\n",
            "신용 점수와의 관계:\n",
            "                  count        mean  median        std  min  max\n",
            "주거 형태                                                           \n",
            "월세                 4050  752.541975   764.0  49.651583  544  824\n",
            "자가                 2241  733.914324   745.0  60.144779  511  818\n",
            "주택 담보 대출 (거주 중)    3633  741.180292   753.0  61.369994  502  825\n",
            "주택 담보 대출 (비거주 중)     76  749.276316   763.0  46.740018  640  805\n",
            "\n",
            "연간 소득과의 관계:\n",
            "                  count          mean      median           std       min  \\\n",
            "주거 형태                                                                       \n",
            "월세                 4050  1.813200e+06  1552536.75  1.067112e+06  267621.0   \n",
            "자가                 2241  1.986144e+06  1635529.50  1.252786e+06  298708.5   \n",
            "주택 담보 대출 (거주 중)    3633  2.667601e+06  2145492.00  1.729243e+06  506862.0   \n",
            "주택 담보 대출 (비거주 중)     76  2.023525e+06  1751397.75  1.123315e+06  467454.0   \n",
            "\n",
            "                         max  \n",
            "주거 형태                         \n",
            "월세                12200962.5  \n",
            "자가                13219294.5  \n",
            "주택 담보 대출 (거주 중)   17229747.0  \n",
            "주택 담보 대출 (비거주 중)   7359651.0  \n",
            "\n",
            "다른 범주형 변수와의 관계:\n",
            "\n",
            "UID와(과)의 관계:\n",
            "UID               TRAIN_00000  TRAIN_00001  TRAIN_00002  TRAIN_00003  \\\n",
            "주거 형태                                                                  \n",
            "월세                   0.000000     0.024691     0.024691     0.024691   \n",
            "자가                   0.044623     0.000000     0.000000     0.000000   \n",
            "주택 담보 대출 (거주 중)      0.000000     0.000000     0.000000     0.000000   \n",
            "주택 담보 대출 (비거주 중)     0.000000     0.000000     0.000000     0.000000   \n",
            "\n",
            "UID               TRAIN_00004  TRAIN_00005  TRAIN_00006  TRAIN_00007  \\\n",
            "주거 형태                                                                  \n",
            "월세                   0.024691     0.000000     0.000000     0.000000   \n",
            "자가                   0.000000     0.000000     0.044623     0.000000   \n",
            "주택 담보 대출 (거주 중)      0.000000     0.027525     0.000000     0.027525   \n",
            "주택 담보 대출 (비거주 중)     0.000000     0.000000     0.000000     0.000000   \n",
            "\n",
            "UID               TRAIN_00008  TRAIN_00009  ...  TRAIN_09990  TRAIN_09991  \\\n",
            "주거 형태                                       ...                             \n",
            "월세                   0.000000     0.000000  ...     0.000000     0.000000   \n",
            "자가                   0.000000     0.044623  ...     0.044623     0.044623   \n",
            "주택 담보 대출 (거주 중)      0.027525     0.000000  ...     0.000000     0.000000   \n",
            "주택 담보 대출 (비거주 중)     0.000000     0.000000  ...     0.000000     0.000000   \n",
            "\n",
            "UID               TRAIN_09992  TRAIN_09993  TRAIN_09994  TRAIN_09995  \\\n",
            "주거 형태                                                                  \n",
            "월세                   0.000000     0.024691     0.000000     0.000000   \n",
            "자가                   0.044623     0.000000     0.000000     0.000000   \n",
            "주택 담보 대출 (거주 중)      0.000000     0.000000     0.027525     0.027525   \n",
            "주택 담보 대출 (비거주 중)     0.000000     0.000000     0.000000     0.000000   \n",
            "\n",
            "UID               TRAIN_09996  TRAIN_09997  TRAIN_09998  TRAIN_09999  \n",
            "주거 형태                                                                 \n",
            "월세                   0.000000     0.000000     0.000000     0.000000  \n",
            "자가                   0.000000     0.000000     0.044623     0.000000  \n",
            "주택 담보 대출 (거주 중)      0.027525     0.027525     0.000000     0.027525  \n",
            "주택 담보 대출 (비거주 중)     0.000000     0.000000     0.000000     0.000000  \n",
            "\n",
            "[4 rows x 10000 columns]\n",
            "\n",
            "현재 직장 근속 연수와(과)의 관계:\n",
            "현재 직장 근속 연수          10년 이상        1년     1년 미만         2년        3년  \\\n",
            "주거 형태                                                                  \n",
            "월세                37.308642  9.456790  4.419753  13.728395  3.135802   \n",
            "자가                36.769299  5.310129  5.488621  13.788487  6.514949   \n",
            "주택 담보 대출 (거주 중)   40.379851  2.091935  5.009634   9.716488  6.853840   \n",
            "주택 담보 대출 (비거주 중)  34.210526  3.947368  5.263158   9.210526  1.315789   \n",
            "\n",
            "현재 직장 근속 연수             4년        5년        6년        7년         8년        9년  \n",
            "주거 형태                                                                          \n",
            "월세                4.024691  5.555556  4.172840  4.716049  11.185185  2.296296  \n",
            "자가                4.149933  9.950915  4.149933  4.730031   6.648817  2.498884  \n",
            "주택 담보 대출 (거주 중)   7.652078  7.569502  2.559868  8.863198   6.083127  3.220479  \n",
            "주택 담보 대출 (비거주 중)  9.210526  7.894737  2.631579  0.000000  23.684211  2.631579  \n",
            "\n",
            "대출 목적와(과)의 관계:\n",
            "대출 목적                결혼 자금     고액 구매       교육비         기타      부채 통합  \\\n",
            "주거 형태                                                                  \n",
            "월세                0.123457  0.790123  0.000000   8.123457  81.925926   \n",
            "자가                0.223115  1.070950  0.089246  15.618028  67.782240   \n",
            "주택 담보 대출 (거주 중)   0.110102  0.330306  0.027525   7.872282  66.143683   \n",
            "주택 담보 대출 (비거주 중)  0.000000  0.000000  0.000000   6.578947  71.052632   \n",
            "\n",
            "대출 목적                사업 대출  소규모 사업 자금     여행 자금       의료비     이사 비용    자동차 구매  \\\n",
            "주거 형태                                                                           \n",
            "월세                1.185185   0.345679  1.802469  1.901235  0.024691  0.864198   \n",
            "자가                2.811245   0.401606  2.320393  1.695672  0.089246  1.026328   \n",
            "주택 담보 대출 (거주 중)   3.798514   0.082576  1.266171  1.018442  0.027525  0.990917   \n",
            "주택 담보 대출 (비거주 중)  6.578947   0.000000  2.631579  7.894737  0.000000  1.315789   \n",
            "\n",
            "대출 목적                주택 개보수     주택 구매     휴가 비용  \n",
            "주거 형태                                            \n",
            "월세                 2.641975  0.197531  0.074074  \n",
            "자가                 6.604195  0.267738  0.000000  \n",
            "주택 담보 대출 (거주 중)   17.946601  0.302780  0.082576  \n",
            "주택 담보 대출 (비거주 중)   2.631579  1.315789  0.000000  \n",
            "\n",
            "데이터 품질 검사:\n",
            "- 이상한 범주값 없음\n",
            "- 범주 분포가 비교적 균형적임 (최대 비율: 40.50%)\n",
            "\n",
            "==================================================\n",
            "\n",
            "===== 현재 직장 근속 연수 분석 =====\n",
            "기본 정보:\n",
            "- 총 데이터 수: 10000\n",
            "- 결측치 수: 0 (0.00%)\n",
            "- 고유 범주 수: 11\n",
            "\n",
            "범주별 빈도:\n",
            "- 10년 이상: 3828 (38.28%)\n",
            "- 2년: 1225 (12.25%)\n",
            "- 8년: 841 (8.41%)\n",
            "- 5년: 729 (7.29%)\n",
            "- 7년: 619 (6.19%)\n",
            "- 1년: 581 (5.81%)\n",
            "- 4년: 541 (5.41%)\n",
            "- 3년: 523 (5.23%)\n",
            "- 1년 미만: 488 (4.88%)\n",
            "- 6년: 357 (3.57%)\n",
            "  ... 그 외 1개 범주\n",
            "\n",
            "타겟 변수(채무 불이행 여부)와의 관계:\n",
            "             count      mean   sum    불이행률(%)\n",
            "현재 직장 근속 연수                                  \n",
            "8년             841  0.493460   415  49.346017\n",
            "1년             581  0.487091   283  48.709122\n",
            "4년             541  0.441774   239  44.177449\n",
            "9년             268  0.425373   114  42.537313\n",
            "3년             523  0.397706   208  39.770554\n",
            "6년             357  0.389356   139  38.935574\n",
            "1년 미만          488  0.381148   186  38.114754\n",
            "7년             619  0.366721   227  36.672052\n",
            "10년 이상        3828  0.286834  1098  28.683386\n",
            "5년             729  0.274348   200  27.434842\n",
            "2년            1225  0.247347   303  24.734694\n",
            "\n",
            "카이제곱 검정 결과:\n",
            "- 카이제곱 값: 303.7451\n",
            "- p-value: 0.0000\n",
            "- 자유도: 10\n",
            "  (p < 0.05: 변수와 타겟 간에 유의한 관계가 있음)\n",
            "\n",
            "주요 수치형 변수와의 관계:\n",
            "\n",
            "신용 점수와의 관계:\n",
            "             count        mean  median        std  min  max\n",
            "현재 직장 근속 연수                                                \n",
            "10년 이상        3828  753.260449   767.0  52.484445  511  825\n",
            "1년             581  744.082616   751.0  50.540527  531  816\n",
            "1년 미만          488  734.172131   744.0  61.934183  505  818\n",
            "2년            1225  745.413061   753.0  51.196573  502  816\n",
            "3년             523  725.021033   729.0  60.969510  533  820\n",
            "4년             541  745.837338   760.0  56.597894  529  822\n",
            "5년             729  707.370370   704.0  67.830044  518  818\n",
            "6년             357  744.789916   755.0  53.694968  582  815\n",
            "7년             619  734.436187   747.0  64.196858  520  820\n",
            "8년             841  755.777646   778.0  50.969242  547  824\n",
            "9년             268  748.052239   760.0  57.517340  520  822\n",
            "\n",
            "연간 소득과의 관계:\n",
            "             count          mean      median           std       min  \\\n",
            "현재 직장 근속 연수                                                            \n",
            "10년 이상        3828  2.309874e+06  1847365.50  1.567365e+06  394207.5   \n",
            "1년             581  1.578861e+06  1419372.00  7.858692e+05  499534.5   \n",
            "1년 미만          488  2.125414e+06  1695477.00  1.379403e+06  376816.5   \n",
            "2년            1225  1.819808e+06  1524427.50  1.185686e+06  267621.0   \n",
            "3년             523  2.213593e+06  1849428.00  1.409380e+06  533112.0   \n",
            "4년             541  2.436030e+06  1961290.50  1.594818e+06  659788.5   \n",
            "5년             729  2.327260e+06  1993950.00  1.376521e+06  408361.5   \n",
            "6년             357  2.096700e+06  1646833.50  1.433670e+06  488704.5   \n",
            "7년             619  2.458050e+06  1970161.50  1.711600e+06  651190.5   \n",
            "8년             841  1.957642e+06  1655145.00  1.051859e+06  512983.5   \n",
            "9년             268  1.958945e+06  1629758.25  1.088126e+06  499527.0   \n",
            "\n",
            "                    max  \n",
            "현재 직장 근속 연수              \n",
            "10년 이상       17229747.0  \n",
            "1년            6129921.0  \n",
            "1년 미만        13243704.0  \n",
            "2년           11999434.5  \n",
            "3년           13552071.0  \n",
            "4년           12089710.5  \n",
            "5년           12979972.5  \n",
            "6년           12200962.5  \n",
            "7년           14082696.0  \n",
            "8년           10238295.0  \n",
            "9년            6625617.0  \n",
            "\n",
            "다른 범주형 변수와의 관계:\n",
            "\n",
            "UID와(과)의 관계:\n",
            "UID          TRAIN_00000  TRAIN_00001  TRAIN_00002  TRAIN_00003  TRAIN_00004  \\\n",
            "현재 직장 근속 연수                                                                    \n",
            "10년 이상          0.026123     0.026123          0.0          0.0     0.000000   \n",
            "1년              0.000000     0.000000          0.0          0.0     0.000000   \n",
            "1년 미만           0.000000     0.000000          0.0          0.0     0.000000   \n",
            "2년              0.000000     0.000000          0.0          0.0     0.081633   \n",
            "3년              0.000000     0.000000          0.0          0.0     0.000000   \n",
            "\n",
            "UID          TRAIN_00005  TRAIN_00006  TRAIN_00007  TRAIN_00008  TRAIN_00009  \\\n",
            "현재 직장 근속 연수                                                                    \n",
            "10년 이상          0.026123          0.0     0.000000     0.000000     0.000000   \n",
            "1년              0.000000          0.0     0.000000     0.000000     0.000000   \n",
            "1년 미만           0.000000          0.0     0.000000     0.000000     0.000000   \n",
            "2년              0.000000          0.0     0.081633     0.000000     0.081633   \n",
            "3년              0.000000          0.0     0.000000     0.191205     0.000000   \n",
            "\n",
            "UID          ...  TRAIN_09990  TRAIN_09991  TRAIN_09992  TRAIN_09993  \\\n",
            "현재 직장 근속 연수  ...                                                       \n",
            "10년 이상       ...     0.000000     0.000000          0.0          0.0   \n",
            "1년           ...     0.172117     0.000000          0.0          0.0   \n",
            "1년 미만        ...     0.000000     0.000000          0.0          0.0   \n",
            "2년           ...     0.000000     0.081633          0.0          0.0   \n",
            "3년           ...     0.000000     0.000000          0.0          0.0   \n",
            "\n",
            "UID          TRAIN_09994  TRAIN_09995  TRAIN_09996  TRAIN_09997  TRAIN_09998  \\\n",
            "현재 직장 근속 연수                                                                    \n",
            "10년 이상          0.026123     0.026123     0.000000     0.026123     0.026123   \n",
            "1년              0.000000     0.000000     0.000000     0.000000     0.000000   \n",
            "1년 미만           0.000000     0.000000     0.000000     0.000000     0.000000   \n",
            "2년              0.000000     0.000000     0.081633     0.000000     0.000000   \n",
            "3년              0.000000     0.000000     0.000000     0.000000     0.000000   \n",
            "\n",
            "UID          TRAIN_09999  \n",
            "현재 직장 근속 연수               \n",
            "10년 이상               0.0  \n",
            "1년                   0.0  \n",
            "1년 미만                0.0  \n",
            "2년                   0.0  \n",
            "3년                   0.0  \n",
            "\n",
            "[5 rows x 10000 columns]\n",
            "... (행이 너무 많아 상위 5개만 출력)\n",
            "\n",
            "주거 형태와(과)의 관계:\n",
            "주거 형태               월세         자가  주택 담보 대출 (거주 중)  주택 담보 대출 (비거주 중)\n",
            "현재 직장 근속 연수                                                         \n",
            "10년 이상       39.472309  21.525601        38.322884          0.679206\n",
            "1년           65.920826  20.481928        13.080895          0.516351\n",
            "1년 미만        36.680328  25.204918        37.295082          0.819672\n",
            "2년           45.387755  25.224490        28.816327          0.571429\n",
            "3년           24.282983  27.915870        47.609943          0.191205\n",
            "... (행이 너무 많아 상위 5개만 출력)\n",
            "\n",
            "대출 목적와(과)의 관계:\n",
            "대출 목적           결혼 자금     고액 구매       교육비         기타      부채 통합     사업 대출  \\\n",
            "현재 직장 근속 연수                                                                 \n",
            "10년 이상       0.182863  0.130617  0.026123  11.233020  71.682341  2.925810   \n",
            "1년           0.172117  0.000000  0.000000   6.884682  87.091222  0.860585   \n",
            "1년 미만        0.000000  0.409836  0.000000  11.270492  77.254098  1.844262   \n",
            "2년           0.244898  0.081633  0.081633   5.877551  67.346939  3.591837   \n",
            "3년           0.382409  0.191205  0.000000  10.516252  73.231358  1.912046   \n",
            "\n",
            "대출 목적        소규모 사업 자금     여행 자금       의료비     이사 비용    자동차 구매     주택 개보수  \\\n",
            "현재 직장 근속 연수                                                                 \n",
            "10년 이상        0.078370  1.802508  0.992685  0.026123  0.574713  10.005225   \n",
            "1년            0.172117  1.032702  0.000000  0.000000  0.344234   3.098107   \n",
            "1년 미만         0.204918  0.204918  1.024590  0.000000  0.614754   7.172131   \n",
            "2년            0.979592  4.734694  1.224490  0.081633  4.244898  11.020408   \n",
            "3년            0.191205  0.956023  0.764818  0.000000  0.956023  10.707457   \n",
            "\n",
            "대출 목적           주택 구매     휴가 비용  \n",
            "현재 직장 근속 연수                      \n",
            "10년 이상       0.287356  0.052247  \n",
            "1년           0.344234  0.000000  \n",
            "1년 미만        0.000000  0.000000  \n",
            "2년           0.163265  0.326531  \n",
            "3년           0.191205  0.000000  \n",
            "... (행이 너무 많아 상위 5개만 출력)\n",
            "\n",
            "데이터 품질 검사:\n",
            "- 이상한 범주값 없음\n",
            "- 범주 분포가 비교적 균형적임 (최대 비율: 38.28%)\n",
            "\n",
            "==================================================\n",
            "\n",
            "===== 대출 목적 분석 =====\n",
            "기본 정보:\n",
            "- 총 데이터 수: 10000\n",
            "- 결측치 수: 0 (0.00%)\n",
            "- 고유 범주 수: 14\n",
            "\n",
            "범주별 빈도:\n",
            "- 부채 통합: 7294 (72.94%)\n",
            "- 기타: 970 (9.70%)\n",
            "- 주택 개보수: 909 (9.09%)\n",
            "- 사업 대출: 254 (2.54%)\n",
            "- 여행 자금: 173 (1.73%)\n",
            "- 의료비: 158 (1.58%)\n",
            "- 자동차 구매: 95 (0.95%)\n",
            "- 고액 구매: 68 (0.68%)\n",
            "- 소규모 사업 자금: 26 (0.26%)\n",
            "- 주택 구매: 26 (0.26%)\n",
            "  ... 그 외 4개 범주\n",
            "\n",
            "타겟 변수(채무 불이행 여부)와의 관계:\n",
            "           count      mean   sum    불이행률(%)\n",
            "대출 목적                                      \n",
            "부채 통합       7294  0.398547  2907  39.854675\n",
            "휴가 비용          6  0.333333     2  33.333333\n",
            "기타           970  0.217526   211  21.752577\n",
            "의료비          158  0.196203    31  19.620253\n",
            "사업 대출        254  0.185039    47  18.503937\n",
            "주택 개보수       909  0.174917   159  17.491749\n",
            "여행 자금        173  0.161850    28  16.184971\n",
            "주택 구매         26  0.153846     4  15.384615\n",
            "결혼 자금         14  0.142857     2  14.285714\n",
            "자동차 구매        95  0.136842    13  13.684211\n",
            "고액 구매         68  0.117647     8  11.764706\n",
            "교육비            3  0.000000     0   0.000000\n",
            "이사 비용          4  0.000000     0   0.000000\n",
            "소규모 사업 자금     26  0.000000     0   0.000000\n",
            "\n",
            "카이제곱 검정 결과:\n",
            "- 카이제곱 값: 407.9927\n",
            "- p-value: 0.0000\n",
            "- 자유도: 13\n",
            "  (p < 0.05: 변수와 타겟 간에 유의한 관계가 있음)\n",
            "\n",
            "주요 수치형 변수와의 관계:\n",
            "\n",
            "신용 점수와의 관계:\n",
            "           count        mean  median        std  min  max\n",
            "대출 목적                                                    \n",
            "결혼 자금         14  738.928571   726.5  52.065734  631  804\n",
            "고액 구매         68  696.705882   687.0  66.981632  538  811\n",
            "교육비            3  739.666667   713.0  46.188022  713  793\n",
            "기타           970  725.387629   742.0  64.560931  518  825\n",
            "부채 통합       7294  746.778585   760.0  55.085179  502  824\n",
            "사업 대출        254  733.527559   747.0  60.250639  520  822\n",
            "소규모 사업 자금     26  754.653846   757.0  48.451991  598  811\n",
            "여행 자금        173  752.341040   760.0  43.424947  629  813\n",
            "의료비          158  743.443038   764.0  59.402384  549  816\n",
            "이사 비용          4  773.250000   763.0  22.559181  760  807\n",
            "자동차 구매        95  733.473684   742.0  57.608333  558  813\n",
            "주택 개보수       909  749.906491   765.0  58.081299  511  822\n",
            "주택 구매         26  739.653846   734.5  61.751724  616  809\n",
            "휴가 비용          6  726.000000   714.0  45.585085  684  802\n",
            "\n",
            "연간 소득과의 관계:\n",
            "           count          mean      median           std        min  \\\n",
            "대출 목적                                                                 \n",
            "결혼 자금         14  1.881032e+06  1378458.75  1.300033e+06   765192.0   \n",
            "고액 구매         68  3.262750e+06  2938898.25  1.210302e+06  1620324.0   \n",
            "교육비            3  1.274890e+06  1351692.00  2.709132e+05   973867.5   \n",
            "기타           970  1.935530e+06  1631256.75  1.094928e+06   376816.5   \n",
            "부채 통합       7294  2.099289e+06  1696507.50  1.391662e+06   267621.0   \n",
            "사업 대출        254  2.438475e+06  1924536.00  1.843718e+06   537394.5   \n",
            "소규모 사업 자금     26  1.755412e+06  1599158.25  9.188871e+05   784432.5   \n",
            "여행 자금        173  1.500296e+06  1346772.00  8.017343e+05   298708.5   \n",
            "의료비          158  2.501299e+06  2074569.75  1.323224e+06   603810.0   \n",
            "이사 비용          4  1.184823e+06   900363.75  7.009001e+05   712543.5   \n",
            "자동차 구매        95  1.685547e+06  1562805.00  7.005894e+05   593097.0   \n",
            "주택 개보수       909  2.918844e+06  2299354.50  1.817176e+06   360528.0   \n",
            "주택 구매         26  1.845822e+06  1709002.50  8.648648e+05   758463.0   \n",
            "휴가 비용          6  2.005046e+06  1708800.00  1.038173e+06   993258.0   \n",
            "\n",
            "                  max  \n",
            "대출 목적                  \n",
            "결혼 자금       5816853.0  \n",
            "고액 구매       5851104.0  \n",
            "교육비         1499110.5  \n",
            "기타         10320694.5  \n",
            "부채 통합      17229747.0  \n",
            "사업 대출      16497990.0  \n",
            "소규모 사업 자금   4485138.0  \n",
            "여행 자금       5400921.0  \n",
            "의료비         7142383.5  \n",
            "이사 비용       2226019.5  \n",
            "자동차 구매      4636726.5  \n",
            "주택 개보수     13552071.0  \n",
            "주택 구매       5248326.0  \n",
            "휴가 비용       3484996.5  \n",
            "\n",
            "다른 범주형 변수와의 관계:\n",
            "\n",
            "UID와(과)의 관계:\n",
            "UID    TRAIN_00000  TRAIN_00001  TRAIN_00002  TRAIN_00003  TRAIN_00004  \\\n",
            "대출 목적                                                                    \n",
            "결혼 자금      0.00000      0.00000      0.00000      0.00000      0.00000   \n",
            "고액 구매      0.00000      0.00000      0.00000      0.00000      0.00000   \n",
            "교육비        0.00000      0.00000      0.00000      0.00000      0.00000   \n",
            "기타         0.00000      0.00000      0.00000      0.00000      0.00000   \n",
            "부채 통합      0.01371      0.01371      0.01371      0.01371      0.01371   \n",
            "\n",
            "UID    TRAIN_00005  TRAIN_00006  TRAIN_00007  TRAIN_00008  TRAIN_00009  ...  \\\n",
            "대출 목적                                                                   ...   \n",
            "결혼 자금      0.00000      0.00000          0.0     0.000000      0.00000  ...   \n",
            "고액 구매      0.00000      0.00000          0.0     0.000000      0.00000  ...   \n",
            "교육비        0.00000      0.00000          0.0     0.000000      0.00000  ...   \n",
            "기타         0.00000      0.00000          0.0     0.103093      0.00000  ...   \n",
            "부채 통합      0.01371      0.01371          0.0     0.000000      0.01371  ...   \n",
            "\n",
            "UID    TRAIN_09990  TRAIN_09991  TRAIN_09992  TRAIN_09993  TRAIN_09994  \\\n",
            "대출 목적                                                                    \n",
            "결혼 자금      0.00000          0.0      0.00000      0.00000      0.00000   \n",
            "고액 구매      0.00000          0.0      0.00000      0.00000      0.00000   \n",
            "교육비        0.00000          0.0      0.00000      0.00000      0.00000   \n",
            "기타         0.00000          0.0      0.00000      0.00000      0.00000   \n",
            "부채 통합      0.01371          0.0      0.01371      0.01371      0.01371   \n",
            "\n",
            "UID    TRAIN_09995  TRAIN_09996  TRAIN_09997  TRAIN_09998  TRAIN_09999  \n",
            "대출 목적                                                                   \n",
            "결혼 자금      0.00000          0.0      0.00000      0.00000          0.0  \n",
            "고액 구매      0.00000          0.0      0.00000      0.00000          0.0  \n",
            "교육비        0.00000          0.0      0.00000      0.00000          0.0  \n",
            "기타         0.00000          0.0      0.00000      0.00000          0.0  \n",
            "부채 통합      0.01371          0.0      0.01371      0.01371          0.0  \n",
            "\n",
            "[5 rows x 10000 columns]\n",
            "... (행이 너무 많아 상위 5개만 출력)\n",
            "\n",
            "주거 형태와(과)의 관계:\n",
            "주거 형태         월세         자가  주택 담보 대출 (거주 중)  주택 담보 대출 (비거주 중)\n",
            "대출 목적                                                         \n",
            "결혼 자금  35.714286  35.714286        28.571429          0.000000\n",
            "고액 구매  47.058824  35.294118        17.647059          0.000000\n",
            "교육비     0.000000  66.666667        33.333333          0.000000\n",
            "기타     33.917526  36.082474        29.484536          0.515464\n",
            "부채 통합  45.489443  20.825336        32.944886          0.740335\n",
            "... (행이 너무 많아 상위 5개만 출력)\n",
            "\n",
            "현재 직장 근속 연수와(과)의 관계:\n",
            "현재 직장 근속 연수     10년 이상        1년     1년 미만         2년         3년        4년  \\\n",
            "대출 목적                                                                        \n",
            "결혼 자금        50.000000  7.142857  0.000000  21.428571  14.285714  0.000000   \n",
            "고액 구매         7.352941  0.000000  2.941176   1.470588   1.470588  2.941176   \n",
            "교육비          33.333333  0.000000  0.000000  33.333333   0.000000  0.000000   \n",
            "기타           44.329897  4.123711  5.670103   7.422680   5.670103  3.092784   \n",
            "부채 통합        37.619962  6.937209  5.168632  11.310666   5.250891  5.785577   \n",
            "\n",
            "현재 직장 근속 연수         5년        6년        7년        8년         9년  \n",
            "대출 목적                                                            \n",
            "결혼 자금         0.000000  0.000000  0.000000  7.142857   0.000000  \n",
            "고액 구매        83.823529  0.000000  0.000000  0.000000   0.000000  \n",
            "교육비           0.000000  0.000000  0.000000  0.000000  33.333333  \n",
            "기타           16.907216  1.340206  5.567010  5.257732   0.618557  \n",
            "부채 통합         4.757335  4.332328  6.416233  9.473540   2.947628  \n",
            "... (행이 너무 많아 상위 5개만 출력)\n",
            "\n",
            "데이터 품질 검사:\n",
            "- 이상한 범주값 없음\n",
            "- 불균형: 가장 많은 범주가 전체의 72.94%\n",
            "\n",
            "==================================================\n",
            "\n",
            "===== 대출 상환 기간 분석 =====\n",
            "기본 정보:\n",
            "- 총 데이터 수: 10000\n",
            "- 결측치 수: 0 (0.00%)\n",
            "- 고유 범주 수: 2\n",
            "\n",
            "범주별 빈도:\n",
            "- 단기 상환: 6975 (69.75%)\n",
            "- 장기 상환: 3025 (30.25%)\n",
            "\n",
            "타겟 변수(채무 불이행 여부)와의 관계:\n",
            "          count      mean   sum    불이행률(%)\n",
            "대출 상환 기간                                  \n",
            "장기 상환      3025  0.422810  1279  42.280992\n",
            "단기 상환      6975  0.305806  2133  30.580645\n",
            "\n",
            "카이제곱 검정 결과:\n",
            "- 카이제곱 값: 127.9804\n",
            "- p-value: 0.0000\n",
            "- 자유도: 1\n",
            "  (p < 0.05: 변수와 타겟 간에 유의한 관계가 있음)\n",
            "\n",
            "주요 수치형 변수와의 관계:\n",
            "\n",
            "신용 점수와의 관계:\n",
            "          count        mean  median        std  min  max\n",
            "대출 상환 기간                                                \n",
            "단기 상환      6975  761.506810   776.0  45.614690  505  825\n",
            "장기 상환      3025  704.343802   702.0  60.521855  502  820\n",
            "\n",
            "연간 소득과의 관계:\n",
            "          count          mean     median           std       min         max\n",
            "대출 상환 기간                                                                    \n",
            "단기 상환      6975  2.060694e+06  1666150.5  1.316972e+06  267621.0  17229747.0\n",
            "장기 상환      3025  2.402065e+06  1969362.0  1.649929e+06  409635.0  16497990.0\n",
            "\n",
            "다른 범주형 변수와의 관계:\n",
            "\n",
            "UID와(과)의 관계:\n",
            "UID       TRAIN_00000  TRAIN_00001  TRAIN_00002  TRAIN_00003  TRAIN_00004  \\\n",
            "대출 상환 기간                                                                    \n",
            "단기 상환        0.014337     0.014337     0.014337     0.014337     0.000000   \n",
            "장기 상환        0.000000     0.000000     0.000000     0.000000     0.033058   \n",
            "\n",
            "UID       TRAIN_00005  TRAIN_00006  TRAIN_00007  TRAIN_00008  TRAIN_00009  \\\n",
            "대출 상환 기간                                                                    \n",
            "단기 상환        0.014337     0.014337     0.000000     0.014337     0.014337   \n",
            "장기 상환        0.000000     0.000000     0.033058     0.000000     0.000000   \n",
            "\n",
            "UID       ...  TRAIN_09990  TRAIN_09991  TRAIN_09992  TRAIN_09993  \\\n",
            "대출 상환 기간  ...                                                       \n",
            "단기 상환     ...     0.014337     0.014337     0.000000     0.014337   \n",
            "장기 상환     ...     0.000000     0.000000     0.033058     0.000000   \n",
            "\n",
            "UID       TRAIN_09994  TRAIN_09995  TRAIN_09996  TRAIN_09997  TRAIN_09998  \\\n",
            "대출 상환 기간                                                                    \n",
            "단기 상환        0.000000     0.014337     0.000000     0.000000     0.014337   \n",
            "장기 상환        0.033058     0.000000     0.033058     0.033058     0.000000   \n",
            "\n",
            "UID       TRAIN_09999  \n",
            "대출 상환 기간               \n",
            "단기 상환        0.000000  \n",
            "장기 상환        0.033058  \n",
            "\n",
            "[2 rows x 10000 columns]\n",
            "\n",
            "주거 형태와(과)의 관계:\n",
            "주거 형태            월세         자가  주택 담보 대출 (거주 중)  주택 담보 대출 (비거주 중)\n",
            "대출 상환 기간                                                         \n",
            "단기 상환     47.297491  20.616487        31.240143          0.845878\n",
            "장기 상환     24.826446  26.545455        48.066116          0.561983\n",
            "\n",
            "현재 직장 근속 연수와(과)의 관계:\n",
            "현재 직장 근속 연수     10년 이상        1년     1년 미만         2년        3년        4년  \\\n",
            "대출 상환 기간                                                                    \n",
            "단기 상환        41.419355  6.308244  4.430108  12.974910  3.526882  4.931900   \n",
            "장기 상환        31.041322  4.661157  5.917355  10.578512  9.157025  6.512397   \n",
            "\n",
            "현재 직장 근속 연수         5년        6년        7년         8년        9년  \n",
            "대출 상환 기간                                                         \n",
            "단기 상환         4.630824  3.526882  5.146953  10.365591  2.738351  \n",
            "장기 상환        13.421488  3.669421  8.595041   3.900826  2.545455  \n",
            "\n",
            "데이터 품질 검사:\n",
            "- 이상한 범주값 없음\n",
            "- 범주 분포가 비교적 균형적임 (최대 비율: 69.75%)\n",
            "\n",
            "==================================================\n",
            "\n",
            "===== 모든 범주형 변수의 타겟 변수 영향력 요약 =====\n",
            "                     chi2       p_value  cramers_v\n",
            "UID          10000.000000  4.952984e-01   1.000000\n",
            "대출 목적          407.992657  4.581772e-79   0.201988\n",
            "현재 직장 근속 연수    303.745130  2.510745e-59   0.174283\n",
            "대출 상환 기간       127.980394  1.133572e-29   0.113128\n",
            "주거 형태           69.215048  6.285324e-15   0.083196\n",
            "\n",
            "* cramers_v: 변수와 타겟 간 연관성 강도 (0~1, 높을수록 강한 연관성)\n",
            "* p_value: 0.05 미만이면 통계적으로 유의미한 관계\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJMmLdU5janT"
      },
      "source": [
        "# 1. 피쳐 엔지니어링"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 변수별 스케일링 추천받아서 한 스케일링"
      ],
      "metadata": {
        "id": "sCy4di-lTQCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# 대출 목적 그룹화 함수\n",
        "def categorize_loan_purpose(purpose):\n",
        "    high_freq = ['부채 통합', '기타', '주택 개보수']\n",
        "    if purpose in high_freq:\n",
        "        return purpose\n",
        "    zero_risk = ['교육비', '소규모 사업 자금', '이사 비용']\n",
        "    low_risk = ['고액 구매', '자동차 구매', '결혼 자금', '주택 구매']\n",
        "    med_risk = ['여행 자금', '주택 개보수', '사업 대출', '의료비']\n",
        "    high_risk = ['휴가 비용']\n",
        "    if purpose in zero_risk:\n",
        "        return '기타_무위험'\n",
        "    elif purpose in low_risk:\n",
        "        return '기타_저위험'\n",
        "    elif purpose in med_risk:\n",
        "        return '기타_중위험'\n",
        "    elif purpose in high_risk:\n",
        "        return '기타_고위험'\n",
        "    else:\n",
        "        return '기타'\n",
        "\n",
        "# 근속 연수 그룹화 함수\n",
        "def categorize_work_years(year_str):\n",
        "    if year_str == '1년 미만':\n",
        "        return '5년 미만'\n",
        "    elif year_str in ['1년', '2년', '3년', '4년']:\n",
        "        return '5년 미만'\n",
        "    elif year_str in ['5년', '6년', '7년', '8년', '9년']:\n",
        "        return '5년 이상 10년 미만'\n",
        "    elif year_str == '10년 이상':\n",
        "        return '10년 이상'\n",
        "    else:\n",
        "        return '기타'\n",
        "\n",
        "# 대출 목적 그룹화 및 원핫인코딩\n",
        "train_df['대출 목적_그룹'] = train_df['대출 목적'].apply(categorize_loan_purpose)\n",
        "loan_purpose_dummies = pd.get_dummies(train_df['대출 목적_그룹'], prefix='목적')\n",
        "train_df = pd.concat([train_df, loan_purpose_dummies], axis=1)\n",
        "train_df = train_df.drop('대출 목적_그룹', axis=1)\n",
        "\n",
        "# 주거 형태 원핫인코딩\n",
        "train_df = pd.get_dummies(train_df, columns=['주거 형태'], prefix='주거 형태')\n",
        "test_df = pd.get_dummies(test_df, columns=['주거 형태'], prefix='주거 형태')\n",
        "\n",
        "# 근속 연수 변환 및 원핫인코딩\n",
        "train_df['근속연수_범주'] = train_df['현재 직장 근속 연수'].apply(categorize_work_years)\n",
        "test_df['근속연수_범주'] = test_df['현재 직장 근속 연수'].apply(categorize_work_years)\n",
        "train_df = pd.get_dummies(train_df, columns=['근속연수_범주'], prefix='근속연수')\n",
        "test_df = pd.get_dummies(test_df, columns=['근속연수_범주'], prefix='근속연수')\n",
        "\n",
        "# 대출 상환 기간 원핫인코딩\n",
        "train_df = pd.get_dummies(train_df, columns=['대출 상환 기간'], prefix='대출상환기간')\n",
        "test_df = pd.get_dummies(test_df, columns=['대출 상환 기간'], prefix='대출상환기간')\n",
        "\n",
        "# 원본 범주형 변수 제거\n",
        "train_df = train_df.drop(['현재 직장 근속 연수', '대출 목적'], axis=1)\n",
        "test_df = test_df.drop(['현재 직장 근속 연수', '대출 목적'], axis=1)\n",
        "\n",
        "# 수치형 변수 스케일링\n",
        "# 스케일링할 변수들 분류\n",
        "log_transform_cols = ['연간 소득', '최대 신용한도', '현재 미상환 신용액', '월 상환 부채액']\n",
        "standard_scaler_cols = ['신용 거래 연수', '현재 대출 잔액']\n",
        "minmax_scaler_cols = ['개설된 신용계좌 수', '마지막 연체 이후 경과 개월 수', '신용 점수']\n",
        "binary_encode_cols = ['체납 세금 압류 횟수', '신용 문제 발생 횟수', '개인 파산 횟수']\n",
        "\n",
        "# 로그 변환 (0값 처리 포함)\n",
        "for col in log_transform_cols:\n",
        "    if col in train_df.columns:\n",
        "        # 0값이 있는 경우 log(x+1) 사용\n",
        "        train_df[f'{col}_log'] = np.log1p(train_df[col])\n",
        "        test_df[f'{col}_log'] = np.log1p(test_df[col])\n",
        "\n",
        "# 표준화 스케일링 (StandardScaler)\n",
        "for col in standard_scaler_cols:\n",
        "    if col in train_df.columns:\n",
        "        scaler = StandardScaler()\n",
        "        train_df[f'{col}_scaled'] = scaler.fit_transform(train_df[[col]])\n",
        "        test_df[f'{col}_scaled'] = scaler.transform(test_df[[col]])\n",
        "\n",
        "# MinMax 스케일링\n",
        "for col in minmax_scaler_cols:\n",
        "    if col in train_df.columns:\n",
        "        minmax = MinMaxScaler()\n",
        "        train_df[f'{col}_minmax'] = minmax.fit_transform(train_df[[col]])\n",
        "        test_df[f'{col}_minmax'] = minmax.transform(test_df[[col]])\n",
        "\n",
        "# 이진 인코딩 (Binary Encoding)\n",
        "for col in binary_encode_cols:\n",
        "    if col in train_df.columns:\n",
        "        train_df[f'{col}_binary'] = (train_df[col] > 0).astype(int)\n",
        "        test_df[f'{col}_binary'] = (test_df[col] > 0).astype(int)\n",
        "\n",
        "# 변환 후 원본 변수 삭제\n",
        "train_df = train_df.drop(log_transform_cols + standard_scaler_cols + minmax_scaler_cols + binary_encode_cols, axis=1)\n",
        "test_df = test_df.drop(log_transform_cols + standard_scaler_cols + minmax_scaler_cols + binary_encode_cols, axis=1)\n",
        "\n",
        "# 최종 데이터셋 확인\n",
        "print(f\"최종 학습 데이터 형태: {train_df.shape}\")\n",
        "print(f\"최종 테스트 데이터 형태: {test_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyuW9wlVTPeY",
        "outputId": "e363ef45-703e-444f-e7cf-af0ed3c73299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 학습 데이터 형태: (10000, 30)\n",
            "최종 테스트 데이터 형태: (2062, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 수정수정코드"
      ],
      "metadata": {
        "id": "zxcBnzKfq79O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# 주거 형태에 위험도 변수 추가하는 함수\n",
        "def add_housing_risk(df):\n",
        "    risk_map = {\n",
        "        '월세': 3,  # 38.49% 불이행률 - 가장 높음\n",
        "        '자가': 2,  # 32.75% 불이행률 - 중간\n",
        "        '주택 담보 대출 (거주 중)': 1,  # 30.47% 불이행률 - 낮음\n",
        "        '주택 담보 대출 (비거주 중)': 0  # 15.79% 불이행률 - 가장 낮음\n",
        "    }\n",
        "    df['주거형태_위험도'] = df['주거 형태'].map(risk_map)\n",
        "    return df\n",
        "\n",
        "# 대출 목적 그룹화 함수 개선 (중복 제거 및 불이행률 기반 그룹화)\n",
        "def categorize_loan_purpose(purpose):\n",
        "    # 빈도가 높은 주요 범주는 별도 유지\n",
        "    high_freq = ['부채 통합', '기타', '주택 개보수']\n",
        "    if purpose in high_freq:\n",
        "        return purpose\n",
        "\n",
        "    # 불이행률 기반 그룹화\n",
        "    zero_risk = ['교육비', '소규모 사업 자금', '이사 비용']  # 0% 불이행\n",
        "    very_low_risk = ['고액 구매', '자동차 구매', '주택 구매', '결혼 자금']  # ~15% 이하\n",
        "    low_risk = ['여행 자금', '의료비', '사업 대출']  # ~16-20%\n",
        "    high_risk = ['휴가 비용']  # 33%\n",
        "\n",
        "    if purpose in zero_risk:\n",
        "        return '기타_무위험'\n",
        "    elif purpose in very_low_risk:\n",
        "        return '기타_매우저위험'\n",
        "    elif purpose in low_risk:\n",
        "        return '기타_저위험'\n",
        "    elif purpose in high_risk:\n",
        "        return '기타_고위험'\n",
        "    else:\n",
        "        return '기타'\n",
        "\n",
        "# 근속 연수 그룹화 함수 개선 (불이행률 기반)\n",
        "def categorize_work_years(year_str):\n",
        "    # 불이행률이 높은 집단 (~42-49%)\n",
        "    high_risk = ['8년', '1년', '4년', '9년']\n",
        "    # 중간 불이행률 집단 (~36-40%)\n",
        "    medium_risk = ['3년', '6년', '1년 미만', '7년']\n",
        "    # 낮은 불이행률 집단 (~24-29%)\n",
        "    low_risk = ['10년 이상', '5년', '2년']\n",
        "\n",
        "    if year_str in high_risk:\n",
        "        return '고위험_근속'\n",
        "    elif year_str in medium_risk:\n",
        "        return '중위험_근속'\n",
        "    elif year_str in low_risk:\n",
        "        return '저위험_근속'\n",
        "    else:\n",
        "        return '기타_근속'\n",
        "\n",
        "# 주거 형태 위험도 추가\n",
        "train_df = add_housing_risk(train_df)\n",
        "test_df = add_housing_risk(test_df)\n",
        "\n",
        "# 대출 목적 그룹화 및 원핫인코딩\n",
        "train_df['대출 목적_그룹'] = train_df['대출 목적'].apply(categorize_loan_purpose)\n",
        "test_df['대출 목적_그룹'] = test_df['대출 목적'].apply(categorize_loan_purpose)  # 테스트셋도 동일하게 적용\n",
        "loan_purpose_dummies = pd.get_dummies(train_df['대출 목적_그룹'], prefix='목적')\n",
        "test_purpose_dummies = pd.get_dummies(test_df['대출 목적_그룹'], prefix='목적')\n",
        "train_df = pd.concat([train_df, loan_purpose_dummies], axis=1)\n",
        "test_df = pd.concat([test_df, test_purpose_dummies], axis=1)\n",
        "\n",
        "# 주거 형태 원핫인코딩\n",
        "train_df = pd.get_dummies(train_df, columns=['주거 형태'], prefix='주거 형태')\n",
        "test_df = pd.get_dummies(test_df, columns=['주거 형태'], prefix='주거 형태')\n",
        "\n",
        "# 근속 연수 변환 및 원핫인코딩\n",
        "train_df['근속연수_범주'] = train_df['현재 직장 근속 연수'].apply(categorize_work_years)\n",
        "test_df['근속연수_범주'] = test_df['현재 직장 근속 연수'].apply(categorize_work_years)\n",
        "train_df = pd.get_dummies(train_df, columns=['근속연수_범주'], prefix='근속연수')\n",
        "test_df = pd.get_dummies(test_df, columns=['근속연수_범주'], prefix='근속연수')\n",
        "\n",
        "# 대출 상환 기간 원핫인코딩\n",
        "train_df = pd.get_dummies(train_df, columns=['대출 상환 기간'], prefix='대출상환기간')\n",
        "test_df = pd.get_dummies(test_df, columns=['대출 상환 기간'], prefix='대출상환기간')\n",
        "\n",
        "# 대출 상환 기간과 신용 점수의 상호작용 변수 추가\n",
        "if '신용 점수' in train_df.columns and '대출상환기간_장기 상환' in train_df.columns:\n",
        "    train_df['상환기간X신용점수'] = train_df['대출상환기간_장기 상환'] * train_df['신용 점수']\n",
        "    test_df['상환기간X신용점수'] = test_df['대출상환기간_장기 상환'] * test_df['신용 점수']\n",
        "\n",
        "# 부채 통합과 신용 점수의 상호작용 변수 추가 (부채 통합이 가장 빈도 높고 불이행률 높음)\n",
        "if '신용 점수' in train_df.columns and '목적_부채 통합' in train_df.columns:\n",
        "    train_df['부채통합X신용점수'] = train_df['목적_부채 통합'] * train_df['신용 점수']\n",
        "    test_df['부채통합X신용점수'] = test_df['목적_부채 통합'] * test_df['신용 점수']\n",
        "\n",
        "# 원본 범주형 변수 제거\n",
        "train_df = train_df.drop(['현재 직장 근속 연수', '대출 목적', '대출 목적_그룹'], axis=1)\n",
        "test_df = test_df.drop(['현재 직장 근속 연수', '대출 목적', '대출 목적_그룹'], axis=1)\n",
        "\n",
        "# 수치형 변수 스케일링\n",
        "# 스케일링할 변수들 분류\n",
        "log_transform_cols = ['연간 소득', '최대 신용한도', '현재 미상환 신용액', '월 상환 부채액']\n",
        "standard_scaler_cols = ['신용 거래 연수', '현재 대출 잔액']\n",
        "minmax_scaler_cols = ['개설된 신용계좌 수', '마지막 연체 이후 경과 개월 수', '신용 점수']\n",
        "binary_encode_cols = ['체납 세금 압류 횟수', '신용 문제 발생 횟수', '개인 파산 횟수']\n",
        "\n",
        "# 로그 변환 (0값 처리 포함)\n",
        "for col in log_transform_cols:\n",
        "    if col in train_df.columns:\n",
        "        # 0값이 있는 경우 log(x+1) 사용\n",
        "        train_df[f'{col}_log'] = np.log1p(train_df[col])\n",
        "        test_df[f'{col}_log'] = np.log1p(test_df[col])\n",
        "\n",
        "# 표준화 스케일링 (StandardScaler)\n",
        "for col in standard_scaler_cols:\n",
        "    if col in train_df.columns:\n",
        "        scaler = StandardScaler()\n",
        "        train_df[f'{col}_scaled'] = scaler.fit_transform(train_df[[col]])\n",
        "        test_df[f'{col}_scaled'] = scaler.transform(test_df[[col]])\n",
        "\n",
        "# MinMax 스케일링\n",
        "for col in minmax_scaler_cols:\n",
        "    if col in train_df.columns:\n",
        "        minmax = MinMaxScaler()\n",
        "        train_df[f'{col}_minmax'] = minmax.fit_transform(train_df[[col]])\n",
        "        test_df[f'{col}_minmax'] = minmax.transform(test_df[[col]])\n",
        "\n",
        "# 이진 인코딩 (Binary Encoding)\n",
        "for col in binary_encode_cols:\n",
        "    if col in train_df.columns:\n",
        "        train_df[f'{col}_binary'] = (train_df[col] > 0).astype(int)\n",
        "        test_df[f'{col}_binary'] = (test_df[col] > 0).astype(int)\n",
        "\n",
        "# 신용 점수 구간화 추가 (신용 점수가 불이행률과 강한 상관관계를 보일 수 있음)\n",
        "if '신용 점수' in train_df.columns:\n",
        "    train_df['신용점수_상위'] = (train_df['신용 점수'] > train_df['신용 점수'].quantile(0.75)).astype(int)\n",
        "    train_df['신용점수_하위'] = (train_df['신용 점수'] < train_df['신용 점수'].quantile(0.25)).astype(int)\n",
        "    test_df['신용점수_상위'] = (test_df['신용 점수'] > train_df['신용 점수'].quantile(0.75)).astype(int)  # 훈련 데이터 기준으로 구간화\n",
        "    test_df['신용점수_하위'] = (test_df['신용 점수'] < train_df['신용 점수'].quantile(0.25)).astype(int)\n",
        "\n",
        "# 변환 후 원본 변수 삭제\n",
        "train_df = train_df.drop(log_transform_cols + standard_scaler_cols + minmax_scaler_cols + binary_encode_cols, axis=1)\n",
        "test_df = test_df.drop(log_transform_cols + standard_scaler_cols + minmax_scaler_cols + binary_encode_cols, axis=1)\n",
        "\n",
        "# 최종 데이터셋 확인\n",
        "print(f\"최종 학습 데이터 형태: {train_df.shape}\")\n",
        "print(f\"최종 테스트 데이터 형태: {test_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6xxTBCOrD6P",
        "outputId": "a27632c6-7c96-4296-f1a2-5af2161e1f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 학습 데이터 형태: (10000, 35)\n",
            "최종 테스트 데이터 형태: (2062, 34)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhzkVrWUjjgk"
      },
      "source": [
        "# 샘플링. SMOTE-Tomek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1UR_VSNjr7d",
        "outputId": "a7e15b8d-748a-4fb1-b685-9fae082eb37b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "채무 불이행 여부\n",
            "0    6246\n",
            "1    6246\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from imblearn.combine import SMOTETomek  # SMOTE-Tomek 임포트\n",
        "\n",
        "# 특성(X)과 타겟(y) 분리\n",
        "# 'UID' 컬럼을 특성에서 제외\n",
        "X = train_df.drop(['채무 불이행 여부', 'UID'], axis=1)\n",
        "y = train_df['채무 불이행 여부']\n",
        "\n",
        "# SMOTE-Tomek 적용\n",
        "# 오버샘플링(SMOTE)과 언더샘플링(Tomek)을 결합한 방식\n",
        "smote_tomek = SMOTETomek(random_state=42)  # random_state 조정 가능\n",
        "X_resampled, y_resampled = smote_tomek.fit_resample(X, y)\n",
        "\n",
        "# 리샘플링된 데이터로 새 DataFrame 생성\n",
        "# SMOTE-Tomek은 새 'UID' 값을 생성하지 않으므로 필요한 경우 별도 처리 필요\n",
        "train_df_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
        "train_df_resampled['채무 불이행 여부'] = y_resampled\n",
        "\n",
        "# 이제 train_df_resampled에 균형 잡힌 데이터셋 포함\n",
        "print(train_df_resampled['채무 불이행 여부'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WvKQDe_NurE"
      },
      "source": [
        "# **모델링**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEQP9jjQUYg_"
      },
      "source": [
        "## 앙상블 DNN(0.6435935712)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PZDpZZRKNw-r",
        "outputId": "be7404a9-5266-49a2-826a-3e315794be53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 준비 중...\n",
            "학습 데이터 특성 수: 33\n",
            "입력 특성 수: 33\n",
            "학습 데이터 크기: (9993, 33)\n",
            "검증 데이터 크기: (2499, 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "앙상블 DNN 모델 학습 중...\n",
            "\n",
            "앙상블 모델 1/3 학습 중...\n",
            "Epoch 1/100\n",
            "313/313 - 9s - 28ms/step - accuracy: 0.5643 - auc: 0.5889 - loss: 0.7322 - val_accuracy: 0.6006 - val_auc: 0.6774 - val_loss: 0.6483 - learning_rate: 1.0000e-03\n",
            "Epoch 2/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.5699 - auc: 0.6038 - loss: 0.6932 - val_accuracy: 0.6307 - val_auc: 0.6792 - val_loss: 0.6474 - learning_rate: 1.0000e-03\n",
            "Epoch 3/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.5823 - auc: 0.6205 - loss: 0.6768 - val_accuracy: 0.6146 - val_auc: 0.6777 - val_loss: 0.6462 - learning_rate: 1.0000e-03\n",
            "Epoch 4/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.5888 - auc: 0.6223 - loss: 0.6751 - val_accuracy: 0.6102 - val_auc: 0.6797 - val_loss: 0.6458 - learning_rate: 1.0000e-03\n",
            "Epoch 5/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.5869 - auc: 0.6291 - loss: 0.6683 - val_accuracy: 0.6242 - val_auc: 0.6796 - val_loss: 0.6451 - learning_rate: 1.0000e-03\n",
            "Epoch 6/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6080 - auc: 0.6468 - loss: 0.6626 - val_accuracy: 0.6471 - val_auc: 0.6905 - val_loss: 0.6415 - learning_rate: 1.0000e-03\n",
            "Epoch 7/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6141 - auc: 0.6552 - loss: 0.6571 - val_accuracy: 0.6146 - val_auc: 0.6919 - val_loss: 0.6478 - learning_rate: 1.0000e-03\n",
            "Epoch 8/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6183 - auc: 0.6583 - loss: 0.6561 - val_accuracy: 0.6146 - val_auc: 0.6733 - val_loss: 0.6555 - learning_rate: 1.0000e-03\n",
            "Epoch 9/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6082 - auc: 0.6505 - loss: 0.6594 - val_accuracy: 0.6146 - val_auc: 0.6885 - val_loss: 0.6424 - learning_rate: 1.0000e-03\n",
            "Epoch 10/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6030 - auc: 0.6471 - loss: 0.6600 - val_accuracy: 0.6146 - val_auc: 0.6924 - val_loss: 0.6425 - learning_rate: 1.0000e-03\n",
            "Epoch 11/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6147 - auc: 0.6558 - loss: 0.6569 - val_accuracy: 0.6126 - val_auc: 0.6921 - val_loss: 0.6450 - learning_rate: 1.0000e-03\n",
            "Epoch 12/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6195 - auc: 0.6612 - loss: 0.6526 - val_accuracy: 0.6146 - val_auc: 0.6928 - val_loss: 0.6562 - learning_rate: 1.0000e-03\n",
            "Epoch 13/100\n",
            "313/313 - 1s - 5ms/step - accuracy: 0.6021 - auc: 0.6452 - loss: 0.6583 - val_accuracy: 0.6479 - val_auc: 0.6953 - val_loss: 0.6468 - learning_rate: 1.0000e-03\n",
            "Epoch 14/100\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.6283 - auc: 0.6715 - loss: 0.6481 - val_accuracy: 0.6467 - val_auc: 0.7158 - val_loss: 0.6294 - learning_rate: 1.0000e-03\n",
            "Epoch 15/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6496 - auc: 0.6958 - loss: 0.6345 - val_accuracy: 0.6711 - val_auc: 0.7373 - val_loss: 0.6078 - learning_rate: 1.0000e-03\n",
            "Epoch 16/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6558 - auc: 0.7095 - loss: 0.6237 - val_accuracy: 0.6655 - val_auc: 0.7408 - val_loss: 0.6071 - learning_rate: 1.0000e-03\n",
            "Epoch 17/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6591 - auc: 0.7152 - loss: 0.6200 - val_accuracy: 0.6531 - val_auc: 0.7387 - val_loss: 0.6272 - learning_rate: 1.0000e-03\n",
            "Epoch 18/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6656 - auc: 0.7236 - loss: 0.6136 - val_accuracy: 0.6647 - val_auc: 0.7542 - val_loss: 0.6048 - learning_rate: 1.0000e-03\n",
            "Epoch 19/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6647 - auc: 0.7243 - loss: 0.6123 - val_accuracy: 0.6827 - val_auc: 0.7562 - val_loss: 0.5929 - learning_rate: 1.0000e-03\n",
            "Epoch 20/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6692 - auc: 0.7263 - loss: 0.6112 - val_accuracy: 0.6727 - val_auc: 0.7567 - val_loss: 0.5917 - learning_rate: 1.0000e-03\n",
            "Epoch 21/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6752 - auc: 0.7349 - loss: 0.6033 - val_accuracy: 0.6943 - val_auc: 0.7629 - val_loss: 0.5894 - learning_rate: 1.0000e-03\n",
            "Epoch 22/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6815 - auc: 0.7402 - loss: 0.6004 - val_accuracy: 0.6995 - val_auc: 0.7706 - val_loss: 0.5723 - learning_rate: 1.0000e-03\n",
            "Epoch 23/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6841 - auc: 0.7456 - loss: 0.5951 - val_accuracy: 0.6731 - val_auc: 0.7395 - val_loss: 0.5992 - learning_rate: 1.0000e-03\n",
            "Epoch 24/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6827 - auc: 0.7435 - loss: 0.5967 - val_accuracy: 0.6987 - val_auc: 0.7725 - val_loss: 0.5680 - learning_rate: 1.0000e-03\n",
            "Epoch 25/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6831 - auc: 0.7500 - loss: 0.5894 - val_accuracy: 0.6715 - val_auc: 0.7695 - val_loss: 0.5853 - learning_rate: 1.0000e-03\n",
            "Epoch 26/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6860 - auc: 0.7506 - loss: 0.5886 - val_accuracy: 0.7067 - val_auc: 0.7797 - val_loss: 0.5660 - learning_rate: 1.0000e-03\n",
            "Epoch 27/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6926 - auc: 0.7576 - loss: 0.5821 - val_accuracy: 0.7071 - val_auc: 0.7808 - val_loss: 0.5589 - learning_rate: 1.0000e-03\n",
            "Epoch 28/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6978 - auc: 0.7614 - loss: 0.5785 - val_accuracy: 0.6963 - val_auc: 0.7639 - val_loss: 0.5751 - learning_rate: 1.0000e-03\n",
            "Epoch 29/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6899 - auc: 0.7599 - loss: 0.5779 - val_accuracy: 0.6719 - val_auc: 0.7844 - val_loss: 0.5884 - learning_rate: 1.0000e-03\n",
            "Epoch 30/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6973 - auc: 0.7642 - loss: 0.5752 - val_accuracy: 0.7079 - val_auc: 0.7806 - val_loss: 0.5571 - learning_rate: 1.0000e-03\n",
            "Epoch 31/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6876 - auc: 0.7574 - loss: 0.5809 - val_accuracy: 0.6699 - val_auc: 0.7881 - val_loss: 0.5921 - learning_rate: 1.0000e-03\n",
            "Epoch 32/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6912 - auc: 0.7607 - loss: 0.5771 - val_accuracy: 0.6967 - val_auc: 0.7813 - val_loss: 0.5699 - learning_rate: 1.0000e-03\n",
            "Epoch 33/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6960 - auc: 0.7648 - loss: 0.5719 - val_accuracy: 0.6799 - val_auc: 0.7795 - val_loss: 0.5847 - learning_rate: 1.0000e-03\n",
            "Epoch 34/100\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.6963 - auc: 0.7662 - loss: 0.5716 - val_accuracy: 0.6170 - val_auc: 0.7628 - val_loss: 0.6403 - learning_rate: 1.0000e-03\n",
            "Epoch 35/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7033 - auc: 0.7754 - loss: 0.5605 - val_accuracy: 0.7071 - val_auc: 0.7937 - val_loss: 0.5443 - learning_rate: 1.0000e-03\n",
            "Epoch 36/100\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.6931 - auc: 0.7645 - loss: 0.5707 - val_accuracy: 0.7127 - val_auc: 0.7933 - val_loss: 0.5459 - learning_rate: 1.0000e-03\n",
            "Epoch 37/100\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.6975 - auc: 0.7643 - loss: 0.5718 - val_accuracy: 0.7031 - val_auc: 0.7892 - val_loss: 0.5485 - learning_rate: 1.0000e-03\n",
            "Epoch 38/100\n",
            "313/313 - 2s - 6ms/step - accuracy: 0.6985 - auc: 0.7711 - loss: 0.5645 - val_accuracy: 0.7027 - val_auc: 0.7860 - val_loss: 0.5459 - learning_rate: 1.0000e-03\n",
            "Epoch 39/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6994 - auc: 0.7701 - loss: 0.5649 - val_accuracy: 0.7039 - val_auc: 0.7868 - val_loss: 0.5487 - learning_rate: 1.0000e-03\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7033 - auc: 0.7702 - loss: 0.5673 - val_accuracy: 0.6903 - val_auc: 0.7645 - val_loss: 0.5783 - learning_rate: 1.0000e-03\n",
            "Epoch 41/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7052 - auc: 0.7771 - loss: 0.5578 - val_accuracy: 0.7023 - val_auc: 0.7842 - val_loss: 0.5478 - learning_rate: 5.0000e-04\n",
            "Epoch 42/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7020 - auc: 0.7772 - loss: 0.5579 - val_accuracy: 0.6511 - val_auc: 0.7844 - val_loss: 0.5949 - learning_rate: 5.0000e-04\n",
            "Epoch 43/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7017 - auc: 0.7767 - loss: 0.5581 - val_accuracy: 0.7039 - val_auc: 0.7977 - val_loss: 0.5355 - learning_rate: 5.0000e-04\n",
            "Epoch 44/100\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.7097 - auc: 0.7793 - loss: 0.5560 - val_accuracy: 0.6611 - val_auc: 0.7875 - val_loss: 0.5879 - learning_rate: 5.0000e-04\n",
            "Epoch 45/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7073 - auc: 0.7802 - loss: 0.5549 - val_accuracy: 0.6883 - val_auc: 0.7958 - val_loss: 0.5607 - learning_rate: 5.0000e-04\n",
            "Epoch 46/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7122 - auc: 0.7824 - loss: 0.5522 - val_accuracy: 0.7155 - val_auc: 0.7972 - val_loss: 0.5315 - learning_rate: 5.0000e-04\n",
            "Epoch 47/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7104 - auc: 0.7829 - loss: 0.5519 - val_accuracy: 0.6931 - val_auc: 0.7982 - val_loss: 0.5513 - learning_rate: 5.0000e-04\n",
            "Epoch 48/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7063 - auc: 0.7807 - loss: 0.5523 - val_accuracy: 0.7215 - val_auc: 0.8026 - val_loss: 0.5292 - learning_rate: 5.0000e-04\n",
            "Epoch 49/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7082 - auc: 0.7809 - loss: 0.5545 - val_accuracy: 0.7159 - val_auc: 0.8012 - val_loss: 0.5328 - learning_rate: 5.0000e-04\n",
            "Epoch 50/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7123 - auc: 0.7863 - loss: 0.5462 - val_accuracy: 0.7115 - val_auc: 0.7952 - val_loss: 0.5332 - learning_rate: 5.0000e-04\n",
            "Epoch 51/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7108 - auc: 0.7821 - loss: 0.5532 - val_accuracy: 0.6831 - val_auc: 0.7828 - val_loss: 0.5697 - learning_rate: 5.0000e-04\n",
            "Epoch 52/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7018 - auc: 0.7777 - loss: 0.5558 - val_accuracy: 0.7111 - val_auc: 0.7891 - val_loss: 0.5499 - learning_rate: 5.0000e-04\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7031 - auc: 0.7768 - loss: 0.5551 - val_accuracy: 0.7131 - val_auc: 0.8017 - val_loss: 0.5326 - learning_rate: 5.0000e-04\n",
            "Epoch 54/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7166 - auc: 0.7895 - loss: 0.5446 - val_accuracy: 0.6971 - val_auc: 0.7998 - val_loss: 0.5503 - learning_rate: 2.5000e-04\n",
            "Epoch 55/100\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.7134 - auc: 0.7905 - loss: 0.5422 - val_accuracy: 0.7191 - val_auc: 0.8027 - val_loss: 0.5275 - learning_rate: 2.5000e-04\n",
            "Epoch 56/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7116 - auc: 0.7855 - loss: 0.5504 - val_accuracy: 0.7179 - val_auc: 0.8017 - val_loss: 0.5321 - learning_rate: 2.5000e-04\n",
            "Epoch 57/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7075 - auc: 0.7834 - loss: 0.5496 - val_accuracy: 0.7147 - val_auc: 0.8043 - val_loss: 0.5326 - learning_rate: 2.5000e-04\n",
            "Epoch 58/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7103 - auc: 0.7873 - loss: 0.5468 - val_accuracy: 0.7223 - val_auc: 0.8031 - val_loss: 0.5294 - learning_rate: 2.5000e-04\n",
            "Epoch 59/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7130 - auc: 0.7899 - loss: 0.5426 - val_accuracy: 0.7255 - val_auc: 0.8040 - val_loss: 0.5252 - learning_rate: 2.5000e-04\n",
            "Epoch 60/100\n",
            "313/313 - 1s - 5ms/step - accuracy: 0.7163 - auc: 0.7894 - loss: 0.5458 - val_accuracy: 0.7127 - val_auc: 0.7957 - val_loss: 0.5356 - learning_rate: 2.5000e-04\n",
            "Epoch 61/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7131 - auc: 0.7887 - loss: 0.5443 - val_accuracy: 0.7095 - val_auc: 0.8031 - val_loss: 0.5278 - learning_rate: 2.5000e-04\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7121 - auc: 0.7861 - loss: 0.5478 - val_accuracy: 0.7123 - val_auc: 0.7982 - val_loss: 0.5377 - learning_rate: 2.5000e-04\n",
            "Epoch 63/100\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.7142 - auc: 0.7878 - loss: 0.5444 - val_accuracy: 0.7227 - val_auc: 0.8027 - val_loss: 0.5234 - learning_rate: 1.2500e-04\n",
            "Epoch 64/100\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.7196 - auc: 0.7950 - loss: 0.5379 - val_accuracy: 0.7235 - val_auc: 0.8043 - val_loss: 0.5235 - learning_rate: 1.2500e-04\n",
            "Epoch 65/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7146 - auc: 0.7908 - loss: 0.5414 - val_accuracy: 0.7151 - val_auc: 0.8027 - val_loss: 0.5260 - learning_rate: 1.2500e-04\n",
            "Epoch 66/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7159 - auc: 0.7917 - loss: 0.5421 - val_accuracy: 0.7243 - val_auc: 0.8042 - val_loss: 0.5229 - learning_rate: 1.2500e-04\n",
            "Epoch 67/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7199 - auc: 0.7928 - loss: 0.5401 - val_accuracy: 0.7263 - val_auc: 0.8047 - val_loss: 0.5240 - learning_rate: 1.2500e-04\n",
            "Epoch 68/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7150 - auc: 0.7917 - loss: 0.5418 - val_accuracy: 0.7199 - val_auc: 0.8037 - val_loss: 0.5293 - learning_rate: 1.2500e-04\n",
            "Epoch 69/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7165 - auc: 0.7934 - loss: 0.5380 - val_accuracy: 0.7251 - val_auc: 0.8043 - val_loss: 0.5228 - learning_rate: 1.2500e-04\n",
            "Epoch 70/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7194 - auc: 0.7932 - loss: 0.5380 - val_accuracy: 0.7191 - val_auc: 0.8037 - val_loss: 0.5222 - learning_rate: 1.2500e-04\n",
            "Epoch 71/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7172 - auc: 0.7896 - loss: 0.5454 - val_accuracy: 0.7195 - val_auc: 0.8042 - val_loss: 0.5252 - learning_rate: 1.2500e-04\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 72: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7161 - auc: 0.7950 - loss: 0.5386 - val_accuracy: 0.7183 - val_auc: 0.8038 - val_loss: 0.5259 - learning_rate: 1.2500e-04\n",
            "Epoch 73/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7158 - auc: 0.7938 - loss: 0.5392 - val_accuracy: 0.7183 - val_auc: 0.8043 - val_loss: 0.5297 - learning_rate: 6.2500e-05\n",
            "Epoch 74/100\n",
            "313/313 - 1s - 5ms/step - accuracy: 0.7176 - auc: 0.7886 - loss: 0.5434 - val_accuracy: 0.7175 - val_auc: 0.8033 - val_loss: 0.5300 - learning_rate: 6.2500e-05\n",
            "Epoch 75/100\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.7128 - auc: 0.7913 - loss: 0.5411 - val_accuracy: 0.7183 - val_auc: 0.8049 - val_loss: 0.5237 - learning_rate: 6.2500e-05\n",
            "Epoch 76/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7201 - auc: 0.7957 - loss: 0.5361 - val_accuracy: 0.7251 - val_auc: 0.8047 - val_loss: 0.5237 - learning_rate: 6.2500e-05\n",
            "Epoch 77/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7145 - auc: 0.7909 - loss: 0.5424 - val_accuracy: 0.7271 - val_auc: 0.8049 - val_loss: 0.5253 - learning_rate: 6.2500e-05\n",
            "Epoch 78/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7164 - auc: 0.7920 - loss: 0.5402 - val_accuracy: 0.7223 - val_auc: 0.8057 - val_loss: 0.5220 - learning_rate: 6.2500e-05\n",
            "Epoch 79/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7196 - auc: 0.7926 - loss: 0.5396 - val_accuracy: 0.7155 - val_auc: 0.8037 - val_loss: 0.5274 - learning_rate: 6.2500e-05\n",
            "Epoch 80/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7226 - auc: 0.7913 - loss: 0.5433 - val_accuracy: 0.7211 - val_auc: 0.8046 - val_loss: 0.5278 - learning_rate: 6.2500e-05\n",
            "Epoch 81/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7150 - auc: 0.7890 - loss: 0.5427 - val_accuracy: 0.7259 - val_auc: 0.8048 - val_loss: 0.5263 - learning_rate: 6.2500e-05\n",
            "Epoch 82/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7152 - auc: 0.7924 - loss: 0.5402 - val_accuracy: 0.7235 - val_auc: 0.8055 - val_loss: 0.5222 - learning_rate: 6.2500e-05\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7170 - auc: 0.7898 - loss: 0.5418 - val_accuracy: 0.7223 - val_auc: 0.8042 - val_loss: 0.5248 - learning_rate: 6.2500e-05\n",
            "Epoch 84/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7246 - auc: 0.7966 - loss: 0.5372 - val_accuracy: 0.7211 - val_auc: 0.8052 - val_loss: 0.5228 - learning_rate: 3.1250e-05\n",
            "Epoch 85/100\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.7172 - auc: 0.7927 - loss: 0.5397 - val_accuracy: 0.7235 - val_auc: 0.8054 - val_loss: 0.5229 - learning_rate: 3.1250e-05\n",
            "Epoch 86/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7184 - auc: 0.7946 - loss: 0.5360 - val_accuracy: 0.7215 - val_auc: 0.8058 - val_loss: 0.5224 - learning_rate: 3.1250e-05\n",
            "Epoch 87/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7180 - auc: 0.7932 - loss: 0.5402 - val_accuracy: 0.7195 - val_auc: 0.8056 - val_loss: 0.5215 - learning_rate: 3.1250e-05\n",
            "Epoch 88/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7175 - auc: 0.7921 - loss: 0.5409 - val_accuracy: 0.7191 - val_auc: 0.8052 - val_loss: 0.5222 - learning_rate: 3.1250e-05\n",
            "Epoch 89/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7270 - auc: 0.7994 - loss: 0.5339 - val_accuracy: 0.7231 - val_auc: 0.8046 - val_loss: 0.5242 - learning_rate: 3.1250e-05\n",
            "Epoch 90/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7166 - auc: 0.7938 - loss: 0.5391 - val_accuracy: 0.7239 - val_auc: 0.8059 - val_loss: 0.5215 - learning_rate: 3.1250e-05\n",
            "Epoch 91/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7210 - auc: 0.7933 - loss: 0.5386 - val_accuracy: 0.7235 - val_auc: 0.8057 - val_loss: 0.5224 - learning_rate: 3.1250e-05\n",
            "Epoch 92/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7138 - auc: 0.7909 - loss: 0.5402 - val_accuracy: 0.7247 - val_auc: 0.8056 - val_loss: 0.5235 - learning_rate: 3.1250e-05\n",
            "Epoch 93/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7196 - auc: 0.7945 - loss: 0.5388 - val_accuracy: 0.7203 - val_auc: 0.8046 - val_loss: 0.5265 - learning_rate: 3.1250e-05\n",
            "Epoch 94/100\n",
            "313/313 - 1s - 5ms/step - accuracy: 0.7155 - auc: 0.7900 - loss: 0.5422 - val_accuracy: 0.7223 - val_auc: 0.8057 - val_loss: 0.5211 - learning_rate: 3.1250e-05\n",
            "Epoch 95/100\n",
            "\n",
            "Epoch 95: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "313/313 - 1s - 5ms/step - accuracy: 0.7174 - auc: 0.7934 - loss: 0.5387 - val_accuracy: 0.7219 - val_auc: 0.8052 - val_loss: 0.5227 - learning_rate: 3.1250e-05\n",
            "Epoch 96/100\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.7144 - auc: 0.7918 - loss: 0.5413 - val_accuracy: 0.7199 - val_auc: 0.8055 - val_loss: 0.5217 - learning_rate: 1.5625e-05\n",
            "Epoch 97/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7216 - auc: 0.7953 - loss: 0.5381 - val_accuracy: 0.7243 - val_auc: 0.8055 - val_loss: 0.5221 - learning_rate: 1.5625e-05\n",
            "Epoch 98/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7201 - auc: 0.7940 - loss: 0.5399 - val_accuracy: 0.7239 - val_auc: 0.8056 - val_loss: 0.5214 - learning_rate: 1.5625e-05\n",
            "Epoch 99/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7229 - auc: 0.7931 - loss: 0.5379 - val_accuracy: 0.7235 - val_auc: 0.8055 - val_loss: 0.5224 - learning_rate: 1.5625e-05\n",
            "Epoch 100/100\n",
            "\n",
            "Epoch 100: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7168 - auc: 0.7900 - loss: 0.5416 - val_accuracy: 0.7219 - val_auc: 0.8057 - val_loss: 0.5219 - learning_rate: 1.5625e-05\n",
            "Epoch 100: early stopping\n",
            "Restoring model weights from the end of the best epoch: 90.\n",
            "\n",
            "앙상블 모델 2/3 학습 중...\n",
            "Epoch 1/100\n",
            "313/313 - 14s - 45ms/step - accuracy: 0.5629 - auc: 0.5895 - loss: 0.7128 - val_accuracy: 0.5962 - val_auc: 0.6448 - val_loss: 0.6574 - learning_rate: 1.0000e-03\n",
            "Epoch 2/100\n",
            "313/313 - 11s - 34ms/step - accuracy: 0.5793 - auc: 0.6187 - loss: 0.6753 - val_accuracy: 0.6062 - val_auc: 0.6592 - val_loss: 0.6500 - learning_rate: 1.0000e-03\n",
            "Epoch 3/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.5884 - auc: 0.6285 - loss: 0.6688 - val_accuracy: 0.5914 - val_auc: 0.6479 - val_loss: 0.6518 - learning_rate: 1.0000e-03\n",
            "Epoch 4/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.5959 - auc: 0.6342 - loss: 0.6677 - val_accuracy: 0.6319 - val_auc: 0.6780 - val_loss: 0.6476 - learning_rate: 1.0000e-03\n",
            "Epoch 5/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.5911 - auc: 0.6374 - loss: 0.6639 - val_accuracy: 0.5970 - val_auc: 0.6636 - val_loss: 0.6523 - learning_rate: 1.0000e-03\n",
            "Epoch 6/100\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.5991 - auc: 0.6374 - loss: 0.6640 - val_accuracy: 0.6347 - val_auc: 0.6766 - val_loss: 0.6459 - learning_rate: 1.0000e-03\n",
            "Epoch 7/100\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.6013 - auc: 0.6414 - loss: 0.6631 - val_accuracy: 0.6182 - val_auc: 0.6776 - val_loss: 0.6469 - learning_rate: 1.0000e-03\n",
            "Epoch 8/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6069 - auc: 0.6484 - loss: 0.6593 - val_accuracy: 0.6407 - val_auc: 0.6795 - val_loss: 0.6452 - learning_rate: 1.0000e-03\n",
            "Epoch 9/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6008 - auc: 0.6440 - loss: 0.6620 - val_accuracy: 0.6427 - val_auc: 0.6864 - val_loss: 0.6455 - learning_rate: 1.0000e-03\n",
            "Epoch 10/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6083 - auc: 0.6504 - loss: 0.6581 - val_accuracy: 0.6427 - val_auc: 0.6848 - val_loss: 0.6461 - learning_rate: 1.0000e-03\n",
            "Epoch 11/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6048 - auc: 0.6477 - loss: 0.6589 - val_accuracy: 0.6146 - val_auc: 0.6789 - val_loss: 0.6551 - learning_rate: 1.0000e-03\n",
            "Epoch 12/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6125 - auc: 0.6527 - loss: 0.6574 - val_accuracy: 0.6146 - val_auc: 0.6897 - val_loss: 0.6429 - learning_rate: 1.0000e-03\n",
            "Epoch 13/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6270 - auc: 0.6622 - loss: 0.6529 - val_accuracy: 0.6146 - val_auc: 0.6971 - val_loss: 0.6593 - learning_rate: 1.0000e-03\n",
            "Epoch 14/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6217 - auc: 0.6617 - loss: 0.6529 - val_accuracy: 0.6146 - val_auc: 0.6949 - val_loss: 0.6623 - learning_rate: 1.0000e-03\n",
            "Epoch 15/100\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.6294 - auc: 0.6695 - loss: 0.6491 - val_accuracy: 0.6419 - val_auc: 0.6877 - val_loss: 0.6418 - learning_rate: 1.0000e-03\n",
            "Epoch 16/100\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.6319 - auc: 0.6757 - loss: 0.6451 - val_accuracy: 0.6575 - val_auc: 0.7192 - val_loss: 0.6260 - learning_rate: 1.0000e-03\n",
            "Epoch 17/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6435 - auc: 0.6867 - loss: 0.6389 - val_accuracy: 0.6198 - val_auc: 0.6924 - val_loss: 0.6477 - learning_rate: 1.0000e-03\n",
            "Epoch 18/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6370 - auc: 0.6807 - loss: 0.6419 - val_accuracy: 0.6639 - val_auc: 0.7298 - val_loss: 0.6155 - learning_rate: 1.0000e-03\n",
            "Epoch 19/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6422 - auc: 0.6930 - loss: 0.6347 - val_accuracy: 0.6491 - val_auc: 0.7318 - val_loss: 0.6277 - learning_rate: 1.0000e-03\n",
            "Epoch 20/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6488 - auc: 0.7006 - loss: 0.6295 - val_accuracy: 0.6679 - val_auc: 0.7346 - val_loss: 0.6083 - learning_rate: 1.0000e-03\n",
            "Epoch 21/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6451 - auc: 0.6993 - loss: 0.6296 - val_accuracy: 0.6687 - val_auc: 0.7299 - val_loss: 0.6151 - learning_rate: 1.0000e-03\n",
            "Epoch 22/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6371 - auc: 0.6930 - loss: 0.6335 - val_accuracy: 0.6751 - val_auc: 0.7487 - val_loss: 0.6043 - learning_rate: 1.0000e-03\n",
            "Epoch 23/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6454 - auc: 0.7051 - loss: 0.6262 - val_accuracy: 0.6723 - val_auc: 0.7457 - val_loss: 0.6053 - learning_rate: 1.0000e-03\n",
            "Epoch 24/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6511 - auc: 0.7094 - loss: 0.6233 - val_accuracy: 0.6158 - val_auc: 0.7405 - val_loss: 0.6848 - learning_rate: 1.0000e-03\n",
            "Epoch 25/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6519 - auc: 0.7073 - loss: 0.6254 - val_accuracy: 0.6166 - val_auc: 0.7514 - val_loss: 0.6955 - learning_rate: 1.0000e-03\n",
            "Epoch 26/100\n",
            "313/313 - 3s - 8ms/step - accuracy: 0.6532 - auc: 0.7164 - loss: 0.6177 - val_accuracy: 0.6979 - val_auc: 0.7636 - val_loss: 0.5891 - learning_rate: 1.0000e-03\n",
            "Epoch 27/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6595 - auc: 0.7209 - loss: 0.6145 - val_accuracy: 0.5650 - val_auc: 0.7449 - val_loss: 0.6790 - learning_rate: 1.0000e-03\n",
            "Epoch 28/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6534 - auc: 0.7138 - loss: 0.6196 - val_accuracy: 0.6607 - val_auc: 0.7588 - val_loss: 0.5925 - learning_rate: 1.0000e-03\n",
            "Epoch 29/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6624 - auc: 0.7199 - loss: 0.6148 - val_accuracy: 0.6619 - val_auc: 0.7647 - val_loss: 0.5978 - learning_rate: 1.0000e-03\n",
            "Epoch 30/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6620 - auc: 0.7196 - loss: 0.6149 - val_accuracy: 0.6783 - val_auc: 0.7556 - val_loss: 0.5917 - learning_rate: 1.0000e-03\n",
            "Epoch 31/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6669 - auc: 0.7278 - loss: 0.6072 - val_accuracy: 0.7047 - val_auc: 0.7775 - val_loss: 0.5673 - learning_rate: 1.0000e-03\n",
            "Epoch 32/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6634 - auc: 0.7241 - loss: 0.6121 - val_accuracy: 0.6975 - val_auc: 0.7782 - val_loss: 0.5927 - learning_rate: 1.0000e-03\n",
            "Epoch 33/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6738 - auc: 0.7332 - loss: 0.6037 - val_accuracy: 0.6871 - val_auc: 0.7730 - val_loss: 0.5910 - learning_rate: 1.0000e-03\n",
            "Epoch 34/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6687 - auc: 0.7280 - loss: 0.6073 - val_accuracy: 0.6947 - val_auc: 0.7675 - val_loss: 0.5777 - learning_rate: 1.0000e-03\n",
            "Epoch 35/100\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.6752 - auc: 0.7373 - loss: 0.5988 - val_accuracy: 0.6983 - val_auc: 0.7802 - val_loss: 0.5769 - learning_rate: 1.0000e-03\n",
            "Epoch 36/100\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.6745 - auc: 0.7382 - loss: 0.5989 - val_accuracy: 0.6899 - val_auc: 0.7778 - val_loss: 0.5926 - learning_rate: 1.0000e-03\n",
            "Epoch 37/100\n",
            "313/313 - 2s - 8ms/step - accuracy: 0.6753 - auc: 0.7387 - loss: 0.5976 - val_accuracy: 0.6663 - val_auc: 0.7811 - val_loss: 0.5913 - learning_rate: 1.0000e-03\n",
            "Epoch 38/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6762 - auc: 0.7422 - loss: 0.5948 - val_accuracy: 0.6647 - val_auc: 0.7542 - val_loss: 0.6000 - learning_rate: 1.0000e-03\n",
            "Epoch 39/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6700 - auc: 0.7376 - loss: 0.5988 - val_accuracy: 0.7059 - val_auc: 0.7852 - val_loss: 0.5604 - learning_rate: 1.0000e-03\n",
            "Epoch 40/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6769 - auc: 0.7411 - loss: 0.5959 - val_accuracy: 0.6238 - val_auc: 0.7658 - val_loss: 0.6338 - learning_rate: 1.0000e-03\n",
            "Epoch 41/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6764 - auc: 0.7410 - loss: 0.5949 - val_accuracy: 0.6651 - val_auc: 0.7798 - val_loss: 0.6053 - learning_rate: 1.0000e-03\n",
            "Epoch 42/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6735 - auc: 0.7424 - loss: 0.5942 - val_accuracy: 0.6991 - val_auc: 0.7849 - val_loss: 0.5710 - learning_rate: 1.0000e-03\n",
            "Epoch 43/100\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.6772 - auc: 0.7449 - loss: 0.5930 - val_accuracy: 0.6467 - val_auc: 0.7727 - val_loss: 0.6296 - learning_rate: 1.0000e-03\n",
            "Epoch 44/100\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.6828 - auc: 0.7488 - loss: 0.5889 - val_accuracy: 0.6991 - val_auc: 0.7857 - val_loss: 0.5603 - learning_rate: 1.0000e-03\n",
            "Epoch 45/100\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.6809 - auc: 0.7451 - loss: 0.5925 - val_accuracy: 0.7111 - val_auc: 0.7885 - val_loss: 0.5555 - learning_rate: 1.0000e-03\n",
            "Epoch 46/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6791 - auc: 0.7469 - loss: 0.5899 - val_accuracy: 0.7027 - val_auc: 0.7884 - val_loss: 0.5770 - learning_rate: 1.0000e-03\n",
            "Epoch 47/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6805 - auc: 0.7464 - loss: 0.5900 - val_accuracy: 0.6887 - val_auc: 0.7666 - val_loss: 0.5646 - learning_rate: 1.0000e-03\n",
            "Epoch 48/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6804 - auc: 0.7465 - loss: 0.5901 - val_accuracy: 0.6655 - val_auc: 0.7823 - val_loss: 0.5926 - learning_rate: 1.0000e-03\n",
            "Epoch 49/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6781 - auc: 0.7450 - loss: 0.5906 - val_accuracy: 0.7007 - val_auc: 0.7848 - val_loss: 0.5523 - learning_rate: 1.0000e-03\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6854 - auc: 0.7528 - loss: 0.5857 - val_accuracy: 0.6991 - val_auc: 0.7860 - val_loss: 0.5800 - learning_rate: 1.0000e-03\n",
            "Epoch 51/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6888 - auc: 0.7582 - loss: 0.5797 - val_accuracy: 0.7163 - val_auc: 0.7909 - val_loss: 0.5498 - learning_rate: 5.0000e-04\n",
            "Epoch 52/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6910 - auc: 0.7629 - loss: 0.5745 - val_accuracy: 0.7175 - val_auc: 0.7925 - val_loss: 0.5507 - learning_rate: 5.0000e-04\n",
            "Epoch 53/100\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.6914 - auc: 0.7638 - loss: 0.5742 - val_accuracy: 0.6507 - val_auc: 0.7929 - val_loss: 0.6152 - learning_rate: 5.0000e-04\n",
            "Epoch 54/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6971 - auc: 0.7672 - loss: 0.5713 - val_accuracy: 0.7115 - val_auc: 0.7947 - val_loss: 0.5456 - learning_rate: 5.0000e-04\n",
            "Epoch 55/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6919 - auc: 0.7647 - loss: 0.5726 - val_accuracy: 0.6647 - val_auc: 0.7907 - val_loss: 0.5818 - learning_rate: 5.0000e-04\n",
            "Epoch 56/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6961 - auc: 0.7660 - loss: 0.5710 - val_accuracy: 0.7011 - val_auc: 0.7854 - val_loss: 0.5498 - learning_rate: 5.0000e-04\n",
            "Epoch 57/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6933 - auc: 0.7632 - loss: 0.5730 - val_accuracy: 0.7139 - val_auc: 0.7923 - val_loss: 0.5509 - learning_rate: 5.0000e-04\n",
            "Epoch 58/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6938 - auc: 0.7655 - loss: 0.5724 - val_accuracy: 0.6975 - val_auc: 0.7948 - val_loss: 0.5646 - learning_rate: 5.0000e-04\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6918 - auc: 0.7657 - loss: 0.5715 - val_accuracy: 0.6883 - val_auc: 0.7947 - val_loss: 0.5618 - learning_rate: 5.0000e-04\n",
            "Epoch 60/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6995 - auc: 0.7711 - loss: 0.5653 - val_accuracy: 0.7191 - val_auc: 0.7965 - val_loss: 0.5442 - learning_rate: 2.5000e-04\n",
            "Epoch 61/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7025 - auc: 0.7723 - loss: 0.5651 - val_accuracy: 0.7111 - val_auc: 0.7955 - val_loss: 0.5536 - learning_rate: 2.5000e-04\n",
            "Epoch 62/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7031 - auc: 0.7732 - loss: 0.5645 - val_accuracy: 0.7175 - val_auc: 0.7952 - val_loss: 0.5408 - learning_rate: 2.5000e-04\n",
            "Epoch 63/100\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.6997 - auc: 0.7700 - loss: 0.5676 - val_accuracy: 0.7139 - val_auc: 0.7969 - val_loss: 0.5403 - learning_rate: 2.5000e-04\n",
            "Epoch 64/100\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.7056 - auc: 0.7757 - loss: 0.5614 - val_accuracy: 0.7135 - val_auc: 0.7958 - val_loss: 0.5411 - learning_rate: 2.5000e-04\n",
            "Epoch 65/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6976 - auc: 0.7733 - loss: 0.5632 - val_accuracy: 0.6931 - val_auc: 0.7939 - val_loss: 0.5656 - learning_rate: 2.5000e-04\n",
            "Epoch 66/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7036 - auc: 0.7764 - loss: 0.5584 - val_accuracy: 0.7071 - val_auc: 0.7888 - val_loss: 0.5476 - learning_rate: 2.5000e-04\n",
            "Epoch 67/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7029 - auc: 0.7760 - loss: 0.5617 - val_accuracy: 0.7091 - val_auc: 0.7939 - val_loss: 0.5495 - learning_rate: 2.5000e-04\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7038 - auc: 0.7763 - loss: 0.5595 - val_accuracy: 0.7015 - val_auc: 0.7908 - val_loss: 0.5610 - learning_rate: 2.5000e-04\n",
            "Epoch 69/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7106 - auc: 0.7811 - loss: 0.5561 - val_accuracy: 0.7155 - val_auc: 0.7978 - val_loss: 0.5384 - learning_rate: 1.2500e-04\n",
            "Epoch 70/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7098 - auc: 0.7788 - loss: 0.5581 - val_accuracy: 0.7107 - val_auc: 0.7968 - val_loss: 0.5391 - learning_rate: 1.2500e-04\n",
            "Epoch 71/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7013 - auc: 0.7758 - loss: 0.5608 - val_accuracy: 0.7143 - val_auc: 0.7982 - val_loss: 0.5387 - learning_rate: 1.2500e-04\n",
            "Epoch 72/100\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.7042 - auc: 0.7793 - loss: 0.5575 - val_accuracy: 0.7127 - val_auc: 0.7961 - val_loss: 0.5401 - learning_rate: 1.2500e-04\n",
            "Epoch 73/100\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.7100 - auc: 0.7806 - loss: 0.5562 - val_accuracy: 0.7199 - val_auc: 0.7975 - val_loss: 0.5373 - learning_rate: 1.2500e-04\n",
            "Epoch 74/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7087 - auc: 0.7829 - loss: 0.5532 - val_accuracy: 0.7139 - val_auc: 0.7985 - val_loss: 0.5369 - learning_rate: 1.2500e-04\n",
            "Epoch 75/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7048 - auc: 0.7732 - loss: 0.5619 - val_accuracy: 0.7167 - val_auc: 0.7981 - val_loss: 0.5385 - learning_rate: 1.2500e-04\n",
            "Epoch 76/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7090 - auc: 0.7808 - loss: 0.5555 - val_accuracy: 0.7199 - val_auc: 0.7976 - val_loss: 0.5392 - learning_rate: 1.2500e-04\n",
            "Epoch 77/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7027 - auc: 0.7765 - loss: 0.5601 - val_accuracy: 0.7159 - val_auc: 0.7947 - val_loss: 0.5421 - learning_rate: 1.2500e-04\n",
            "Epoch 78/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7053 - auc: 0.7806 - loss: 0.5560 - val_accuracy: 0.7183 - val_auc: 0.7968 - val_loss: 0.5390 - learning_rate: 1.2500e-04\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 79: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7109 - auc: 0.7818 - loss: 0.5554 - val_accuracy: 0.7159 - val_auc: 0.7982 - val_loss: 0.5388 - learning_rate: 1.2500e-04\n",
            "Epoch 80/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7033 - auc: 0.7789 - loss: 0.5573 - val_accuracy: 0.7131 - val_auc: 0.7987 - val_loss: 0.5362 - learning_rate: 6.2500e-05\n",
            "Epoch 81/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7131 - auc: 0.7841 - loss: 0.5515 - val_accuracy: 0.7195 - val_auc: 0.7988 - val_loss: 0.5383 - learning_rate: 6.2500e-05\n",
            "Epoch 82/100\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.7131 - auc: 0.7845 - loss: 0.5521 - val_accuracy: 0.7191 - val_auc: 0.7985 - val_loss: 0.5397 - learning_rate: 6.2500e-05\n",
            "Epoch 83/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7077 - auc: 0.7809 - loss: 0.5548 - val_accuracy: 0.7219 - val_auc: 0.7988 - val_loss: 0.5377 - learning_rate: 6.2500e-05\n",
            "Epoch 84/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7054 - auc: 0.7802 - loss: 0.5541 - val_accuracy: 0.7191 - val_auc: 0.7981 - val_loss: 0.5382 - learning_rate: 6.2500e-05\n",
            "Epoch 85/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7037 - auc: 0.7777 - loss: 0.5582 - val_accuracy: 0.7139 - val_auc: 0.7971 - val_loss: 0.5424 - learning_rate: 6.2500e-05\n",
            "Epoch 86/100\n",
            "\n",
            "Epoch 86: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7100 - auc: 0.7840 - loss: 0.5529 - val_accuracy: 0.7183 - val_auc: 0.7986 - val_loss: 0.5383 - learning_rate: 6.2500e-05\n",
            "Epoch 87/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7095 - auc: 0.7811 - loss: 0.5550 - val_accuracy: 0.7179 - val_auc: 0.7989 - val_loss: 0.5380 - learning_rate: 3.1250e-05\n",
            "Epoch 88/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7069 - auc: 0.7796 - loss: 0.5559 - val_accuracy: 0.7211 - val_auc: 0.7982 - val_loss: 0.5378 - learning_rate: 3.1250e-05\n",
            "Epoch 89/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7032 - auc: 0.7789 - loss: 0.5556 - val_accuracy: 0.7227 - val_auc: 0.7975 - val_loss: 0.5388 - learning_rate: 3.1250e-05\n",
            "Epoch 90/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7127 - auc: 0.7830 - loss: 0.5526 - val_accuracy: 0.7211 - val_auc: 0.7969 - val_loss: 0.5426 - learning_rate: 3.1250e-05\n",
            "Epoch 91/100\n",
            "\n",
            "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7097 - auc: 0.7820 - loss: 0.5532 - val_accuracy: 0.7211 - val_auc: 0.7980 - val_loss: 0.5388 - learning_rate: 3.1250e-05\n",
            "Epoch 92/100\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.7091 - auc: 0.7820 - loss: 0.5525 - val_accuracy: 0.7207 - val_auc: 0.7983 - val_loss: 0.5377 - learning_rate: 1.5625e-05\n",
            "Epoch 93/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7084 - auc: 0.7828 - loss: 0.5510 - val_accuracy: 0.7223 - val_auc: 0.7980 - val_loss: 0.5387 - learning_rate: 1.5625e-05\n",
            "Epoch 94/100\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.7063 - auc: 0.7797 - loss: 0.5568 - val_accuracy: 0.7191 - val_auc: 0.7986 - val_loss: 0.5383 - learning_rate: 1.5625e-05\n",
            "Epoch 95/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7107 - auc: 0.7881 - loss: 0.5480 - val_accuracy: 0.7231 - val_auc: 0.7982 - val_loss: 0.5404 - learning_rate: 1.5625e-05\n",
            "Epoch 96/100\n",
            "\n",
            "Epoch 96: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7107 - auc: 0.7824 - loss: 0.5536 - val_accuracy: 0.7203 - val_auc: 0.7986 - val_loss: 0.5373 - learning_rate: 1.5625e-05\n",
            "Epoch 97/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7087 - auc: 0.7839 - loss: 0.5521 - val_accuracy: 0.7199 - val_auc: 0.7987 - val_loss: 0.5376 - learning_rate: 1.0000e-05\n",
            "Epoch 97: early stopping\n",
            "Restoring model weights from the end of the best epoch: 87.\n",
            "\n",
            "앙상블 모델 3/3 학습 중...\n",
            "Epoch 1/100\n",
            "313/313 - 11s - 34ms/step - accuracy: 0.5668 - auc: 0.5947 - loss: 0.7149 - val_accuracy: 0.6146 - val_auc: 0.6770 - val_loss: 0.6489 - learning_rate: 1.0000e-03\n",
            "Epoch 2/100\n",
            "313/313 - 3s - 10ms/step - accuracy: 0.5960 - auc: 0.6312 - loss: 0.6702 - val_accuracy: 0.6407 - val_auc: 0.6817 - val_loss: 0.6449 - learning_rate: 1.0000e-03\n",
            "Epoch 3/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6009 - auc: 0.6372 - loss: 0.6673 - val_accuracy: 0.6291 - val_auc: 0.6784 - val_loss: 0.6459 - learning_rate: 1.0000e-03\n",
            "Epoch 4/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6031 - auc: 0.6425 - loss: 0.6635 - val_accuracy: 0.6355 - val_auc: 0.6852 - val_loss: 0.6436 - learning_rate: 1.0000e-03\n",
            "Epoch 5/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6154 - auc: 0.6536 - loss: 0.6587 - val_accuracy: 0.6146 - val_auc: 0.6895 - val_loss: 0.6482 - learning_rate: 1.0000e-03\n",
            "Epoch 6/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6360 - auc: 0.6746 - loss: 0.6475 - val_accuracy: 0.6146 - val_auc: 0.6845 - val_loss: 0.6542 - learning_rate: 1.0000e-03\n",
            "Epoch 7/100\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.6221 - auc: 0.6587 - loss: 0.6554 - val_accuracy: 0.6146 - val_auc: 0.6972 - val_loss: 0.6484 - learning_rate: 1.0000e-03\n",
            "Epoch 8/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6411 - auc: 0.6792 - loss: 0.6444 - val_accuracy: 0.6146 - val_auc: 0.6689 - val_loss: 0.6864 - learning_rate: 1.0000e-03\n",
            "Epoch 9/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6500 - auc: 0.6928 - loss: 0.6358 - val_accuracy: 0.6651 - val_auc: 0.7243 - val_loss: 0.6185 - learning_rate: 1.0000e-03\n",
            "Epoch 10/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6489 - auc: 0.7011 - loss: 0.6295 - val_accuracy: 0.6295 - val_auc: 0.7346 - val_loss: 0.6450 - learning_rate: 1.0000e-03\n",
            "Epoch 11/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6552 - auc: 0.7082 - loss: 0.6250 - val_accuracy: 0.5430 - val_auc: 0.7138 - val_loss: 0.6906 - learning_rate: 1.0000e-03\n",
            "Epoch 12/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6664 - auc: 0.7185 - loss: 0.6169 - val_accuracy: 0.5150 - val_auc: 0.7148 - val_loss: 0.7327 - learning_rate: 1.0000e-03\n",
            "Epoch 13/100\n",
            "313/313 - 1s - 5ms/step - accuracy: 0.6727 - auc: 0.7299 - loss: 0.6082 - val_accuracy: 0.6459 - val_auc: 0.7440 - val_loss: 0.6600 - learning_rate: 1.0000e-03\n",
            "Epoch 14/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6751 - auc: 0.7292 - loss: 0.6088 - val_accuracy: 0.6447 - val_auc: 0.7303 - val_loss: 0.6152 - learning_rate: 1.0000e-03\n",
            "Epoch 15/100\n",
            "313/313 - 1s - 5ms/step - accuracy: 0.6743 - auc: 0.7367 - loss: 0.6006 - val_accuracy: 0.6423 - val_auc: 0.7382 - val_loss: 0.6291 - learning_rate: 1.0000e-03\n",
            "Epoch 16/100\n",
            "313/313 - 1s - 5ms/step - accuracy: 0.6845 - auc: 0.7439 - loss: 0.5954 - val_accuracy: 0.6963 - val_auc: 0.7640 - val_loss: 0.5851 - learning_rate: 1.0000e-03\n",
            "Epoch 17/100\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.6815 - auc: 0.7443 - loss: 0.5953 - val_accuracy: 0.6230 - val_auc: 0.7641 - val_loss: 0.8893 - learning_rate: 1.0000e-03\n",
            "Epoch 18/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6875 - auc: 0.7516 - loss: 0.5874 - val_accuracy: 0.6387 - val_auc: 0.7570 - val_loss: 0.6622 - learning_rate: 1.0000e-03\n",
            "Epoch 19/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6881 - auc: 0.7529 - loss: 0.5843 - val_accuracy: 0.6747 - val_auc: 0.7574 - val_loss: 0.6245 - learning_rate: 1.0000e-03\n",
            "Epoch 20/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6901 - auc: 0.7558 - loss: 0.5841 - val_accuracy: 0.6367 - val_auc: 0.7790 - val_loss: 0.6770 - learning_rate: 1.0000e-03\n",
            "Epoch 21/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6882 - auc: 0.7538 - loss: 0.5831 - val_accuracy: 0.6979 - val_auc: 0.7744 - val_loss: 0.5659 - learning_rate: 1.0000e-03\n",
            "Epoch 22/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6975 - auc: 0.7594 - loss: 0.5765 - val_accuracy: 0.6651 - val_auc: 0.7836 - val_loss: 0.5840 - learning_rate: 1.0000e-03\n",
            "Epoch 23/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6947 - auc: 0.7617 - loss: 0.5744 - val_accuracy: 0.5742 - val_auc: 0.7415 - val_loss: 0.6901 - learning_rate: 1.0000e-03\n",
            "Epoch 24/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6976 - auc: 0.7633 - loss: 0.5744 - val_accuracy: 0.7175 - val_auc: 0.7893 - val_loss: 0.5482 - learning_rate: 1.0000e-03\n",
            "Epoch 25/100\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.6990 - auc: 0.7680 - loss: 0.5697 - val_accuracy: 0.7103 - val_auc: 0.7888 - val_loss: 0.5421 - learning_rate: 1.0000e-03\n",
            "Epoch 26/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6975 - auc: 0.7656 - loss: 0.5699 - val_accuracy: 0.6871 - val_auc: 0.7776 - val_loss: 0.5684 - learning_rate: 1.0000e-03\n",
            "Epoch 27/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.6973 - auc: 0.7675 - loss: 0.5673 - val_accuracy: 0.6591 - val_auc: 0.7606 - val_loss: 0.6021 - learning_rate: 1.0000e-03\n",
            "Epoch 28/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7008 - auc: 0.7678 - loss: 0.5690 - val_accuracy: 0.7159 - val_auc: 0.7966 - val_loss: 0.5427 - learning_rate: 1.0000e-03\n",
            "Epoch 29/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6925 - auc: 0.7634 - loss: 0.5721 - val_accuracy: 0.7123 - val_auc: 0.7912 - val_loss: 0.5400 - learning_rate: 1.0000e-03\n",
            "Epoch 30/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6963 - auc: 0.7662 - loss: 0.5695 - val_accuracy: 0.6983 - val_auc: 0.7930 - val_loss: 0.5520 - learning_rate: 1.0000e-03\n",
            "Epoch 31/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6935 - auc: 0.7630 - loss: 0.5700 - val_accuracy: 0.6531 - val_auc: 0.7726 - val_loss: 0.5928 - learning_rate: 1.0000e-03\n",
            "Epoch 32/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6952 - auc: 0.7665 - loss: 0.5682 - val_accuracy: 0.6387 - val_auc: 0.7676 - val_loss: 0.7086 - learning_rate: 1.0000e-03\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6993 - auc: 0.7678 - loss: 0.5680 - val_accuracy: 0.5750 - val_auc: 0.7690 - val_loss: 0.6911 - learning_rate: 1.0000e-03\n",
            "Epoch 34/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.6998 - auc: 0.7739 - loss: 0.5594 - val_accuracy: 0.7039 - val_auc: 0.7918 - val_loss: 0.5469 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.7023 - auc: 0.7763 - loss: 0.5577 - val_accuracy: 0.6859 - val_auc: 0.7983 - val_loss: 0.5701 - learning_rate: 5.0000e-04\n",
            "Epoch 36/100\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.7101 - auc: 0.7859 - loss: 0.5474 - val_accuracy: 0.5714 - val_auc: 0.7365 - val_loss: 0.7373 - learning_rate: 5.0000e-04\n",
            "Epoch 37/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7027 - auc: 0.7769 - loss: 0.5574 - val_accuracy: 0.7075 - val_auc: 0.7913 - val_loss: 0.5451 - learning_rate: 5.0000e-04\n",
            "Epoch 38/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7013 - auc: 0.7777 - loss: 0.5560 - val_accuracy: 0.7191 - val_auc: 0.8005 - val_loss: 0.5327 - learning_rate: 5.0000e-04\n",
            "Epoch 39/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7092 - auc: 0.7836 - loss: 0.5490 - val_accuracy: 0.7075 - val_auc: 0.7930 - val_loss: 0.5415 - learning_rate: 5.0000e-04\n",
            "Epoch 40/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7044 - auc: 0.7819 - loss: 0.5525 - val_accuracy: 0.7135 - val_auc: 0.7950 - val_loss: 0.5365 - learning_rate: 5.0000e-04\n",
            "Epoch 41/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7068 - auc: 0.7798 - loss: 0.5519 - val_accuracy: 0.6991 - val_auc: 0.8002 - val_loss: 0.5451 - learning_rate: 5.0000e-04\n",
            "Epoch 42/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7058 - auc: 0.7810 - loss: 0.5543 - val_accuracy: 0.7135 - val_auc: 0.7950 - val_loss: 0.5391 - learning_rate: 5.0000e-04\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7109 - auc: 0.7809 - loss: 0.5508 - val_accuracy: 0.6463 - val_auc: 0.7818 - val_loss: 0.7072 - learning_rate: 5.0000e-04\n",
            "Epoch 44/100\n",
            "313/313 - 1s - 5ms/step - accuracy: 0.7122 - auc: 0.7843 - loss: 0.5489 - val_accuracy: 0.6747 - val_auc: 0.7907 - val_loss: 0.5669 - learning_rate: 2.5000e-04\n",
            "Epoch 45/100\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.7072 - auc: 0.7837 - loss: 0.5493 - val_accuracy: 0.7299 - val_auc: 0.8012 - val_loss: 0.5274 - learning_rate: 2.5000e-04\n",
            "Epoch 46/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7089 - auc: 0.7874 - loss: 0.5421 - val_accuracy: 0.7031 - val_auc: 0.7998 - val_loss: 0.5386 - learning_rate: 2.5000e-04\n",
            "Epoch 47/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7120 - auc: 0.7871 - loss: 0.5450 - val_accuracy: 0.7191 - val_auc: 0.7997 - val_loss: 0.5273 - learning_rate: 2.5000e-04\n",
            "Epoch 48/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7105 - auc: 0.7871 - loss: 0.5436 - val_accuracy: 0.7167 - val_auc: 0.8040 - val_loss: 0.5279 - learning_rate: 2.5000e-04\n",
            "Epoch 49/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7145 - auc: 0.7871 - loss: 0.5441 - val_accuracy: 0.6943 - val_auc: 0.7982 - val_loss: 0.5527 - learning_rate: 2.5000e-04\n",
            "Epoch 50/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7153 - auc: 0.7918 - loss: 0.5417 - val_accuracy: 0.6767 - val_auc: 0.7978 - val_loss: 0.5597 - learning_rate: 2.5000e-04\n",
            "Epoch 51/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7145 - auc: 0.7878 - loss: 0.5448 - val_accuracy: 0.7215 - val_auc: 0.8009 - val_loss: 0.5312 - learning_rate: 2.5000e-04\n",
            "Epoch 52/100\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7095 - auc: 0.7872 - loss: 0.5439 - val_accuracy: 0.7175 - val_auc: 0.8024 - val_loss: 0.5232 - learning_rate: 2.5000e-04\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.7150 - auc: 0.7882 - loss: 0.5427 - val_accuracy: 0.7151 - val_auc: 0.8024 - val_loss: 0.5280 - learning_rate: 2.5000e-04\n",
            "Epoch 54/100\n",
            "313/313 - 1s - 5ms/step - accuracy: 0.7183 - auc: 0.7928 - loss: 0.5399 - val_accuracy: 0.7183 - val_auc: 0.8019 - val_loss: 0.5305 - learning_rate: 1.2500e-04\n",
            "Epoch 55/100\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.7176 - auc: 0.7912 - loss: 0.5399 - val_accuracy: 0.7103 - val_auc: 0.8037 - val_loss: 0.5325 - learning_rate: 1.2500e-04\n",
            "Epoch 56/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7201 - auc: 0.7933 - loss: 0.5388 - val_accuracy: 0.7215 - val_auc: 0.8038 - val_loss: 0.5212 - learning_rate: 1.2500e-04\n",
            "Epoch 57/100\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7235 - auc: 0.7937 - loss: 0.5388 - val_accuracy: 0.7215 - val_auc: 0.8033 - val_loss: 0.5222 - learning_rate: 1.2500e-04\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 58: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7210 - auc: 0.7966 - loss: 0.5345 - val_accuracy: 0.7279 - val_auc: 0.8008 - val_loss: 0.5240 - learning_rate: 1.2500e-04\n",
            "Epoch 58: early stopping\n",
            "Restoring model weights from the end of the best epoch: 48.\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\n",
            "앙상블 DNN 모델 성능:\n",
            "ROC AUC: 0.8043\n",
            "정확도: 0.7163\n",
            "정밀도: 0.7265\n",
            "재현율: 0.6934\n",
            "F1 점수: 0.7095\n",
            "\n",
            "테스트 데이터 예측 중...\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "예측 결과가 '제출용_앙상블_DNN.csv'로 저장되었습니다.\n",
            "예측 완료!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# GPU 설정\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# 간소화된 데이터 준비 함수\n",
        "def prepare_data(train_df_processed, test_df_processed=None):\n",
        "    \"\"\"이미 전처리된 데이터를 학습/검증용으로 분할\"\"\"\n",
        "    print(\"데이터 준비 중...\")\n",
        "\n",
        "    # 테스트 UID 추출 및 저장\n",
        "    test_uid = None\n",
        "    if test_df_processed is not None and \"UID\" in test_df_processed.columns:\n",
        "        test_uid = test_df_processed[[\"UID\"]].copy()\n",
        "        test_df_processed = test_df_processed.drop(columns=[\"UID\"])\n",
        "\n",
        "    # X, y 분리\n",
        "    X = train_df_processed.drop(columns=[\"채무 불이행 여부\"])\n",
        "    y = train_df_processed[\"채무 불이행 여부\"]\n",
        "\n",
        "    # 특성 이름 저장\n",
        "    feature_names = X.columns.tolist()\n",
        "    print(f\"학습 데이터 특성 수: {len(feature_names)}\")\n",
        "\n",
        "    # 학습 및 검증 데이터 분할\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    return (X_train, X_val, y_train, y_val,\n",
        "            X.shape[1], feature_names, test_df_processed, test_uid)\n",
        "\n",
        "# 앙상블 DNN 모델 구현\n",
        "def create_ensemble_dnn_models(input_dim, n_models=3):\n",
        "    \"\"\"여러 DNN 모델 생성 (앙상블용)\"\"\"\n",
        "    models = []\n",
        "\n",
        "    # 다양한 구조의 DNN 모델 생성\n",
        "    for i in range(n_models):\n",
        "        if i == 0:\n",
        "            # 첫 번째 모델 - 얕은 구조\n",
        "            model = Sequential([\n",
        "                Dense(64, activation='relu', input_shape=(input_dim,)),\n",
        "                BatchNormalization(),\n",
        "                Dropout(0.3),\n",
        "                Dense(32, activation='relu'),\n",
        "                BatchNormalization(),\n",
        "                Dropout(0.2),\n",
        "                Dense(1, activation='sigmoid')\n",
        "            ])\n",
        "        elif i == 1:\n",
        "            # 두 번째 모델 - 깊은 구조\n",
        "            model = Sequential([\n",
        "                Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "                BatchNormalization(),\n",
        "                Dropout(0.4),\n",
        "                Dense(64, activation='relu'),\n",
        "                BatchNormalization(),\n",
        "                Dropout(0.3),\n",
        "                Dense(32, activation='relu'),\n",
        "                BatchNormalization(),\n",
        "                Dropout(0.2),\n",
        "                Dense(16, activation='relu'),\n",
        "                BatchNormalization(),\n",
        "                Dense(1, activation='sigmoid')\n",
        "            ])\n",
        "        else:\n",
        "            # 세 번째 모델 - 중간 구조\n",
        "            model = Sequential([\n",
        "                Dense(96, activation='relu', input_shape=(input_dim,)),\n",
        "                BatchNormalization(),\n",
        "                Dropout(0.3),\n",
        "                Dense(48, activation='relu'),\n",
        "                BatchNormalization(),\n",
        "                Dropout(0.3),\n",
        "                Dense(24, activation='relu'),\n",
        "                BatchNormalization(),\n",
        "                Dense(1, activation='sigmoid')\n",
        "            ])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=0.001),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        "        )\n",
        "\n",
        "        models.append(model)\n",
        "\n",
        "    return models\n",
        "\n",
        "# 앙상블 예측 함수\n",
        "def ensemble_predict(models, X_data):\n",
        "    \"\"\"앙상블 모델의 예측 평균\"\"\"\n",
        "    predictions = np.zeros((X_data.shape[0], 1))\n",
        "\n",
        "    for model in models:\n",
        "        predictions += model.predict(X_data)\n",
        "\n",
        "    # 평균 계산\n",
        "    predictions /= len(models)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# 앙상블 모델 학습 및 평가\n",
        "def train_and_evaluate_ensemble(models, X_train, y_train, X_val, y_val, epochs=100, batch_size=32):\n",
        "    \"\"\"앙상블 모델 학습 및 평가\"\"\"\n",
        "    print(\"\\n앙상블 DNN 모델 학습 중...\")\n",
        "\n",
        "    # 콜백 설정\n",
        "    callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_auc',\n",
        "            patience=10,\n",
        "            mode='max',\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_auc',\n",
        "            factor=0.5,\n",
        "            patience=5,\n",
        "            mode='max',\n",
        "            min_lr=1e-5,\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # 각 모델 학습\n",
        "    trained_models = []\n",
        "    for i, model in enumerate(models):\n",
        "        print(f\"\\n앙상블 모델 {i+1}/{len(models)} 학습 중...\")\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_val, y_val),\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=callbacks,\n",
        "            verbose=2\n",
        "        )\n",
        "        trained_models.append(model)\n",
        "\n",
        "    # 앙상블 예측\n",
        "    y_pred_proba = ensemble_predict(trained_models, X_val)\n",
        "\n",
        "    # 이진 예측 (0.5 임계값 사용)\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    # 성능 지표 계산\n",
        "    auc = roc_auc_score(y_val, y_pred_proba)\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    precision = precision_score(y_val, y_pred)\n",
        "    recall = recall_score(y_val, y_pred)\n",
        "    f1 = f1_score(y_val, y_pred)\n",
        "\n",
        "    print(\"\\n앙상블 DNN 모델 성능:\")\n",
        "    print(f\"ROC AUC: {auc:.4f}\")\n",
        "    print(f\"정확도: {accuracy:.4f}\")\n",
        "    print(f\"정밀도: {precision:.4f}\")\n",
        "    print(f\"재현율: {recall:.4f}\")\n",
        "    print(f\"F1 점수: {f1:.4f}\")\n",
        "\n",
        "    return trained_models\n",
        "\n",
        "# 테스트 데이터 예측 함수\n",
        "def predict_on_test(ensemble_models, test_df, feature_names, test_uid):\n",
        "    \"\"\"테스트 데이터 예측 및 결과 파일 생성\"\"\"\n",
        "    print(\"\\n테스트 데이터 예측 중...\")\n",
        "\n",
        "    # 특성 일치 확인 및 처리\n",
        "    for feature in feature_names:\n",
        "        if feature not in test_df.columns:\n",
        "            print(f\"누락된 특성 감지: {feature} - 0으로 채움\")\n",
        "            test_df[feature] = 0\n",
        "\n",
        "    # 학습에 사용된 특성만 선택하여 동일한 순서로 정렬\n",
        "    X_test = test_df[feature_names]\n",
        "\n",
        "    # 앙상블 예측\n",
        "    y_pred_proba = ensemble_predict(ensemble_models, X_test)\n",
        "\n",
        "    # 결과 데이터프레임 생성\n",
        "    result_df = pd.DataFrame({\n",
        "        \"UID\": test_uid[\"UID\"],\n",
        "        \"채무 불이행 확률\": y_pred_proba.flatten()\n",
        "    })\n",
        "\n",
        "    # 결과 저장\n",
        "    output_path = \"제출용_앙상블_DNN.csv\"\n",
        "    result_df.to_csv(output_path, index=False)\n",
        "    print(f\"예측 결과가 '{output_path}'로 저장되었습니다.\")\n",
        "\n",
        "    return result_df\n",
        "\n",
        "# 메인 실행 함수\n",
        "def run_ensemble_model(train_df_processed, test_df_processed):\n",
        "    \"\"\"앙상블 딥러닝 모델 실행\"\"\"\n",
        "    # 이미 전처리된 데이터 준비\n",
        "    results = prepare_data(train_df_processed, test_df_processed)\n",
        "    X_train, X_val, y_train, y_val, input_dim, feature_names, test_df_processed, test_uid = results\n",
        "\n",
        "    print(f\"입력 특성 수: {input_dim}\")\n",
        "    print(f\"학습 데이터 크기: {X_train.shape}\")\n",
        "    print(f\"검증 데이터 크기: {X_val.shape}\")\n",
        "\n",
        "    # 앙상블 DNN 모델 생성 및 학습\n",
        "    ensemble_models = create_ensemble_dnn_models(input_dim)\n",
        "    trained_ensemble_models = train_and_evaluate_ensemble(\n",
        "        ensemble_models, X_train, y_train, X_val, y_val\n",
        "    )\n",
        "\n",
        "    # 테스트 데이터 예측 및 제출 파일 생성\n",
        "    result_df = predict_on_test(\n",
        "        trained_ensemble_models, test_df_processed, feature_names, test_uid\n",
        "    )\n",
        "\n",
        "    print(\"예측 완료!\")\n",
        "    return result_df\n",
        "\n",
        "# 메인 실행 부분\n",
        "if __name__ == \"__main__\":\n",
        "    # 완전히 전처리된 데이터셋으로 직접 모델 실행\n",
        "    result_df = run_ensemble_model(train_df_resampled, test_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1B-nl7_G6kaWmtMNRjmLlQNwKXnPLVcRu",
      "authorship_tag": "ABX9TyPavp9l49xw20m8uaxBhgB5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}